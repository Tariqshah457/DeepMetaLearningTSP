{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, json\n",
    "import solver\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from cell import ConvLSTMCell\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/largefeatures/large200.pickle\")\n",
    "# # Drop rows with NA\n",
    "# rowsBefore = df.shape[0]\n",
    "# df = df.dropna()\n",
    "# print(\"Dropped %d rows due to None values\" % (rowsBefore - df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDeepWalkInstance(path):\n",
    "    file = open(path, \"r\")\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    nodeCount = None\n",
    "    shape = None\n",
    "    \n",
    "    instance = None\n",
    "    \n",
    "    for line in file:\n",
    "        if i == 0:\n",
    "            split = line.split(\" \")\n",
    "            nodeCount = int(split[0])\n",
    "            length = int(split[1])\n",
    "            \n",
    "            instance = np.zeros(shape=(nodeCount, length))\n",
    "        else:\n",
    "            split = line.split(\" \")\n",
    "            \n",
    "            node = split[0]\n",
    "            encoding = np.array(list(map(float, split[1:])))\n",
    "            \n",
    "            instance[i - 1] = encoding\n",
    "            \n",
    "        i += 1\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    return instance\n",
    "\n",
    "def loadDeepWalkInstances(path):\n",
    "    instances = []\n",
    "    names = []\n",
    "    for file in glob.glob(path + \"*.deep\"):\n",
    "        try:\n",
    "            instance = loadDeepWalkInstance(file)\n",
    "            split = os.path.splitext(os.path.splitext(os.path.basename(file))[0])\n",
    "            modifier = split[1][-1:]\n",
    "            name = split[0] + modifier\n",
    "\n",
    "            instances.append(instance)\n",
    "            names.append(name)\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    return instances, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances, names = loadDeepWalkInstances(\"../data/deep300/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2901"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2880"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"name\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SIZE = 300\n",
    "INSTANCE_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 300)\n",
      "Instance rd400p is too large\n",
      "(442, 300)\n",
      "Instance pcb442p is too large\n",
      "(431, 300)\n",
      "Instance gr431p is too large\n",
      "(318, 300)\n",
      "Instance lin318p is too large\n",
      "(561, 300)\n",
      "Instance pa561p is too large\n",
      "(403, 300)\n",
      "Instance rbg403p is too large\n",
      "(666, 300)\n",
      "Instance gr666p is too large\n",
      "(417, 300)\n",
      "Instance fl417p is too large\n",
      "(493, 300)\n",
      "Instance d493p is too large\n",
      "(358, 300)\n",
      "Instance rbg358p is too large\n",
      "(443, 300)\n",
      "Instance rbg443p is too large\n",
      "(323, 300)\n",
      "Instance rbg323p is too large\n",
      "(439, 300)\n",
      "Instance pr439p is too large\n"
     ]
    }
   ],
   "source": [
    "# Merge in DeepWalk data\n",
    "dwInstances = pd.DataFrame(columns=[\"name\", \"deepWalk\", \"sequenceLength\"])\n",
    "reshapedInstances = []\n",
    "for index, name in enumerate(names):\n",
    "    instance = instances[index]\n",
    "    instance = instance.reshape(-1)\n",
    "    \n",
    "    size = instance.shape[0]\n",
    "    \n",
    "    if name == \"pr2392p\":\n",
    "        continue\n",
    "    \n",
    "    if size >= INSTANCE_SIZE * MAX_SIZE:\n",
    "        print(instances[index].shape)\n",
    "        print(\"Instance %s is too large\" % (name))\n",
    "        continue\n",
    "    \n",
    "    zeroed = np.zeros((INSTANCE_SIZE * MAX_SIZE))\n",
    "    zeroed[0: size] = instance\n",
    "    \n",
    "#     instance = scale(zeroed.astype('float64')).reshape(MAX_SIZE, MAX_SIZE)\n",
    "    instance = zeroed.astype('float64').reshape(MAX_SIZE, INSTANCE_SIZE)\n",
    "        \n",
    "#     reshapedInstances.append(scale(zeroed.astype('float64')).reshape(MAX_SIZE, MAX_SIZE))\n",
    "    \n",
    "#     reshapedInstances.append(instance)\n",
    "#     instance = scale(instance.astype('float64'),axis=1)\n",
    "    dwInstances = dwInstances.append(pd.DataFrame([[name, instance, size]], columns=[\"name\", \"deepWalk\", \"sequenceLength\"]))\n",
    "    \n",
    "dwInstances = dwInstances.reset_index().drop(\"index\", axis=1)\n",
    "df = pd.merge(df, dwInstances, on=\"name\")\n",
    "df = df.drop(\"costs\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2818"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"name\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle(\"../data/largefeatures/deep300large200noscaleReshaped.pickle\")\n",
    "# df = pd.read_pickle(\"../data/largefeatures/deeplarge200.pickle\")\n",
    "# df = pd.read_pickle(\"../data/largefeatures/deep128large200noscaleReshaped.pickle\")\n",
    "df = pd.read_pickle(\"../data/largefeatures/deep300large200noscaleReshaped.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df[\"metadata.isAsymmetric\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1724"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"name\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "minCostIndices = df[[\"heuristics.tabuCosts\", \"heuristics.simulatedAnnealingCosts\", \"heuristics.graspCosts\", \"heuristics.geneticCosts\", \"heuristics.antColonyCosts\"]].idxmin(axis=1)\n",
    "# minCostIndices = df[[\"heuristics.tabuCosts\", \"heuristics.simulatedAnnealingCosts\", \"heuristics.geneticCosts\", \"heuristics.antColonyCosts\"]].idxmin(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'heuristics.antColonyCosts': 82,\n",
       "         'heuristics.geneticCosts': 1,\n",
       "         'heuristics.graspCosts': 1298,\n",
       "         'heuristics.simulatedAnnealingCosts': 10,\n",
       "         'heuristics.tabuCosts': 333})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(minCostIndices.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array(df[\"deepWalk\"].tolist())\n",
    "sequenceLengths = np.array(df[\"sequenceLength\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "costValues = df[[\"heuristics.tabuCosts\", \"heuristics.simulatedAnnealingCosts\", \"heuristics.graspCosts\", \"heuristics.geneticCosts\", \"heuristics.antColonyCosts\"]].values\n",
    "indexRankings = costValues.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 4, 1, 3],\n",
       "       [0, 2, 4, 1, 3],\n",
       "       [0, 2, 4, 1, 3],\n",
       "       ..., \n",
       "       [2, 1, 0, 4, 3],\n",
       "       [0, 4, 2, 3, 1],\n",
       "       [1, 3, 2, 0, 4]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexRankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intLabels = LabelEncoder().fit_transform(minCostIndices).reshape(-1, 1)\n",
    "# # 5 values for 5 different heuristics\n",
    "# # Drop grasp from analysis\n",
    "# outputs = OneHotEncoder(sparse=False, n_values=5).fit_transform(intLabels)\n",
    "\n",
    "# inputs = df\n",
    "\n",
    "size = df.shape[0]\n",
    "# Test data is separated in cleaning stage\n",
    "trainSize = int(size * 0.75)\n",
    "validSize = size - trainSize\n",
    "\n",
    "inputsTrain = inputs[0:trainSize]\n",
    "lengthsTrain = sequenceLengths[0:trainSize]\n",
    "outputsTrainUnnorm = indexRankings[0:trainSize]\n",
    "outputsTrain = normalize(outputsTrainUnnorm)\n",
    "\n",
    "inputsValid = inputs[trainSize:]\n",
    "lengthsValid = sequenceLengths[trainSize:]\n",
    "outputsValidUnnorm = indexRankings[trainSize:]\n",
    "outputsValid = normalize(outputsValidUnnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "N1 = trainSize\n",
    "LABEL_COUNT = 5\n",
    "\n",
    "NODES1 = 512\n",
    "NODES2 = 512\n",
    "NODES3 = 256\n",
    "NODES4 = 256\n",
    "NODES5 = 128\n",
    "NODES6 = 128\n",
    "NODES7 = 64\n",
    "\n",
    "LSTM_SIZE = 150\n",
    "LSTM_LAYER_COUNT = 2\n",
    "LSTM_DROPOUT_PROB = 0.7\n",
    "\n",
    "ALPHA = 0.001\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "STD = 0.1\n",
    "\n",
    "LEARNING_RATE = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input function for training\n",
    "inputFunc = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"input\": inputsTrain.astype(np.float32), \"length\": lengthsTrain.astype(np.int32)}, y=outputsTrainUnnorm.astype(np.float32),\n",
    "#     batch_size=BATCH_SIZE, num_epochs=EPOCHS, shuffle=True)\n",
    "    num_epochs=EPOCHS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputsTrain[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputsTrain[0][200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "def network(xDict, mode):\n",
    "    x = xDict[\"input\"]\n",
    "        \n",
    "    length = xDict[\"length\"]\n",
    "    \n",
    "    print(x.shape)\n",
    "        \n",
    "    # Batch size, timeseries, shape, channels\n",
    "    x = tf.reshape(x, shape=[-1, MAX_SIZE, INSTANCE_SIZE, 1])\n",
    "    \n",
    "    print(x.shape)\n",
    "\n",
    "#     if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "#         x = tf.nn.dropout(x, LSTM_DROPOUT_PROB)\n",
    " \n",
    "#     with tf.variable_scope('lstm1'):\n",
    "#         initialCell = tf.contrib.rnn.LSTMBlockFusedCell(LSTM_SIZE)\n",
    "#     initialCell = tf.contrib.rnn.Conv2DLSTMCell(input_shape=(300, 300), output_channels=LSTM_SIZE, kernel_shape=(5,5))\n",
    "    cell = ConvLSTMCell([INSTANCE_SIZE], 1, [5])\n",
    "    lstmOutput, state = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32, sequence_length=length)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=lstmOutput, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    \n",
    "#     lstmOutput, state = tf.nn.dynamic_rnn(initialCell, x, dtype=tf.float32, sequence_length=length)\n",
    "        \n",
    "#         lstmOutput, _ = initialCell(x, dtype=tf.float32, sequence_length=length)\n",
    "#         lstmOutput, _ = initialCell(x, dtype=tf.float32)\n",
    "        \n",
    "#         if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "#             lstmOutput = tf.nn.dropout(lstmOutput, LSTM_DROPOUT_PROB)\n",
    "#     if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "#         initialCell = tf.contrib.rnn.DropoutWrapper(initialCell, input_keep_prob=LSTM_DROPOUT_PROB, output_keep_prob=LSTM_DROPOUT_PROB, state_keep_prob=LSTM_DROPOUT_PROB, variational_recurrent=True, input_size=x.shape[2], dtype=tf.float64)\n",
    "    \n",
    "#     with tf.variable_scope('lstm2'):\n",
    "#         secondCell = tf.contrib.rnn.LSTMBlockFusedCell(LSTM_SIZE)\n",
    "        \n",
    "#         lstmOutput, _ = secondCell(lstmOutput, dtype=tf.float32)\n",
    "        \n",
    "#         if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "#             lstmOutput = tf.nn.dropout(lstmOutput, LSTM_DROPOUT_PROB)\n",
    "            \n",
    "#     with tf.variable_scope('lstm3'):\n",
    "#         thirdCell = tf.contrib.rnn.LSTMBlockFusedCell(LSTM_SIZE)\n",
    "        \n",
    "#         lstmOutput, _ = thirdCell(lstmOutput, dtype=tf.float32)\n",
    "        \n",
    "#         if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "#             lstmOutput = tf.nn.dropout(lstmOutput, LSTM_DROPOUT_PROB)\n",
    "            \n",
    "#     with tf.variable_scope('lstm4'):\n",
    "#         fourthCell = tf.contrib.rnn.LSTMBlockFusedCell(LSTM_SIZE)\n",
    "        \n",
    "#         lstmOutput, _ = fourthCell(lstmOutput, dtype=tf.float32)\n",
    "        \n",
    "#         if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "#             lstmOutput = tf.nn.dropout(lstmOutput, LSTM_DROPOUT_PROB)\n",
    "            \n",
    "#     with tf.variable_scope('lstm5'):\n",
    "#         fifthCell = tf.contrib.rnn.LSTMBlockFusedCell(LSTM_SIZE)\n",
    "        \n",
    "#         lstmOutput, _ = fifthCell(lstmOutput, dtype=tf.float32)\n",
    "        \n",
    "#         if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "#             lstmOutput = tf.nn.dropout(lstmOutput, LSTM_DROPOUT_PROB)\n",
    "            \n",
    "#     with tf.variable_scope('lstm6'):\n",
    "#         sixthCell = tf.contrib.rnn.LSTMBlockFusedCell(LSTM_SIZE)\n",
    "        \n",
    "#         lstmOutput, _ = sixthCell(lstmOutput, dtype=tf.float32)\n",
    "        \n",
    "#         if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "#             lstmOutput = tf.nn.dropout(lstmOutput, LSTM_DROPOUT_PROB)\n",
    "        \n",
    "#         if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "#             secondCell = tf.contrib.rnn.DropoutWrapper(secondCell, input_keep_prob=LSTM_DROPOUT_PROB, output_keep_prob=LSTM_DROPOUT_PROB, state_keep_prob=LSTM_DROPOUT_PROB, variational_recurrent=True, input_size=initialCell.output_size, dtype=tf.float64)\n",
    "        \n",
    "#     stackedLstm = tf.contrib.rnn.MultiRNNCell([initialCell, secondCell])\n",
    "        \n",
    "#     lstmOutput, _ = tf.nn.dynamic_rnn(stackedLstm, x, dtype=tf.float64, sequence_length=length)\n",
    "    \n",
    "    flatten = tf.contrib.layers.flatten(pool2)\n",
    "    \n",
    "    regularizer = tf.contrib.layers.l2_regularizer(scale=ALPHA)\n",
    "    \n",
    "    # Hidden fully connected layer\n",
    "#     layer1 = tf.layers.dense(flatten, NODES1, kernel_regularizer=regularizer, activation=tf.nn.relu)\n",
    "#     layer2 = tf.layers.dense(layer1, NODES2, kernel_regularizer=regularizer, activation=tf.nn.relu)\n",
    "#     layer3 = tf.layers.dense(layer2, NODES3, kernel_regularizer=regularizer, activation=tf.nn.relu)\n",
    "    layer1 = tf.layers.dense(flatten, NODES1, activation=tf.nn.relu)\n",
    "    layer2 = tf.layers.dense(layer1, NODES2, activation=tf.nn.relu)\n",
    "    layer3 = tf.layers.dense(layer2, NODES3, activation=tf.nn.relu)\n",
    "    layer4 = tf.layers.dense(layer3, NODES4, activation=tf.nn.relu)\n",
    "    layer5 = tf.layers.dense(layer4, NODES5, activation=tf.nn.relu)\n",
    "    layer6 = tf.layers.dense(layer5, NODES6, activation=tf.nn.relu)\n",
    "    layer7 = tf.layers.dense(layer6, NODES7, activation=tf.nn.relu)\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    outLayer = tf.layers.dense(layer7, LABEL_COUNT)\n",
    "    return outLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kullback-Leibler Divergence, as per https://stackoverflow.com/a/43298483\n",
    "def klDivergence(p, q):\n",
    "    pClipped = tf.clip_by_value(p, 1e-10, 1.0)\n",
    "    qClipped = tf.clip_by_value(q, 1e-10, 1.0)\n",
    "    return tf.reduce_sum(pClipped * tf.log(pClipped/qClipped))\n",
    "\n",
    "# Loss function based off of Jensen-Shannon Divergence\n",
    "def loss(label, prediction):\n",
    "    mean = 0.5 * (label + prediction)\n",
    "    return 0.5 * klDivergence(label, mean) + 0.5 * klDivergence(prediction, mean)\n",
    "\n",
    "def log2(x):\n",
    "    numerator = tf.log(x)\n",
    "    denominator = tf.log(tf.constant(2, dtype=numerator.dtype))\n",
    "    return numerator / denominator\n",
    "\n",
    "def listNetLoss(label, prediction):\n",
    "    softMaxLabel = tf.nn.softmax(label)\n",
    "    softMaxPrediction = tf.nn.softmax(prediction)\n",
    "    return -tf.reduce_mean(softMaxLabel * tf.log(softMaxPrediction))\n",
    "\n",
    "def listMLE(label, prediction):\n",
    "    sortedPrediction = tf.gather(prediction, tf.nn.top_k(label, k=5).indices)\n",
    "    final = tf.log(tf.reduce_sum(tf.exp(sortedPrediction)))\n",
    "    return tf.reduce_sum(final - sortedPrediction)\n",
    "\n",
    "def listMLE2Loss(labels, predictions, length, length64):\n",
    "    i = tf.constant(0, dtype=tf.int32)\n",
    "    innerSum = tf.constant(0, dtype=tf.float32)\n",
    "    \n",
    "    def loop(label, prediction, i, innerSum):\n",
    "        return tf.add(i, 1), tf.add(innerSum, listMLE2(label, prediction))\n",
    "    \n",
    "    cond = lambda i, _: tf.less(i, length)\n",
    "    operation = lambda i, innerSum: loop(labels[i], predictions[i], i, innerSum)\n",
    "    result = tf.while_loop(cond, operation, [i, innerSum])\n",
    "\n",
    "    return result[1]/length64\n",
    "#     return tf.constant(1.0, dtype=tf.float64) * labels + predictions\n",
    "\n",
    "def listMLE2(label, prediction):\n",
    "    # Length of vectors\n",
    "    k = tf.constant(LABEL_COUNT, dtype=tf.int32)\n",
    "    \n",
    "    sortedPrediction = tf.gather(prediction, tf.nn.top_k(label, k=k).indices)\n",
    "    \n",
    "    j = tf.constant(0, dtype=tf.int32)\n",
    "    innerSum = tf.constant(0, dtype=tf.float32)\n",
    "    cond = lambda j, _: tf.less(j, k)\n",
    "    operation = lambda j, innerSum: listMLE2Loop(sortedPrediction, j, k, innerSum)\n",
    "    result = tf.while_loop(cond, operation, [j, innerSum])\n",
    "    \n",
    "    print(result[1].shape)\n",
    "    \n",
    "    return -result[1]\n",
    "    \n",
    "def listMLE2Loop(sortedPrediction, j, k, innerSum):\n",
    "    return tf.add(j, 1), tf.add(innerSum, listMLE2Inner(sortedPrediction, j, k))\n",
    "\n",
    "def listMLE2Inner(sortedPrediction, j, k):\n",
    "    numerator = tf.exp(tf.gather(sortedPrediction, j))\n",
    "    denominator = tf.reduce_sum(tf.exp(sortedPrediction[j:k]))\n",
    "    \n",
    "    return tf.log(numerator/denominator)\n",
    "\n",
    "# Builds an integer ranking out of a 1-D tensor\n",
    "def convertPredToRank(prediction):\n",
    "    return tf.cast(tf.nn.top_k(prediction, k=5).indices, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy metric using Normalized Discounted Cumulative Gain, as per https://github.com/shiba24/learning2rank/\n",
    "def ndcg(labels, predictions, k=5):\n",
    "    topK = tf.nn.top_k(labels, k=5)\n",
    "    sortedValues = topK.values\n",
    "    sortedIndices = topK.indices\n",
    "#         print(labelSorted)\n",
    "#         labelSorted = sorted(label, reverse=True)\n",
    "    ideal_dcg = 0\n",
    "    for i in range(k):\n",
    "#             ideal_dcg += (2 ** labelSorted[:i] - 1.) / log2(tf.cast(i + 2, tf.float64))\n",
    "        ideal_dcg += (tf.cast(sortedValues[i] + 1, tf.float32)) / log2(tf.cast(i + 2, tf.float32))\n",
    "    dcg = 0\n",
    "#         argsort_indices = np.argsort(predictions)[::-1]\n",
    "#         argsort_indices = tf.nn.top_k(predictions, k=5).indices\n",
    "#         print(argsort_indices)\n",
    "    for i in range(k):\n",
    "        dcg += (tf.gather(predictions, sortedIndices[i]) + 1) / log2(tf.cast(i + 2, tf.float32))\n",
    "#         dcg += (predictions[i] + 1) / log2(tf.cast(i + 2, tf.float64))\n",
    "    return dcg / ideal_dcg\n",
    "\n",
    "def spearmanCorrelation(label, prediction):\n",
    "    length = tf.cast(tf.shape(prediction)[0], tf.float32)\n",
    "    sumVal = tf.reduce_sum(tf.square(tf.subtract(prediction, label)))\n",
    "    return 1 - 6 * sumVal / (length ** 3 - length)\n",
    "\n",
    "# Bound Spearman coeff. between 0 and 1\n",
    "def boundedSpearman(label, prediction):\n",
    "    return (spearmanCorrelation(label, prediction) + 1.)/2\n",
    "\n",
    "def top1Match(label, prediction):\n",
    "    return tf.cast(tf.equal(label[0], prediction[0]), tf.float32)\n",
    "\n",
    "def top2Match(label, prediction):\n",
    "    sameFirstOrSecond = tf.logical_or(tf.equal(label[0], prediction[0]), tf.equal(label[1], prediction[1]))\n",
    "    sameFirstAndSecond = tf.logical_or(tf.equal(label[1], prediction[0]), tf.equal(label[0], prediction[1]))\n",
    "    return tf.cast(tf.logical_or(sameFirstOrSecond, sameFirstAndSecond), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the model function (following TF Estimator Template)\n",
    "# def modelFunc(features, labels, mode):\n",
    "#     # Build the neural network\n",
    "#     logits = network(features)\n",
    "    \n",
    "# #     resizedLogits = tf.reshape(logits, shape=[-1, MAX_SIZE * MAX_SIZE, 1])\n",
    "    \n",
    "#     # Predictions\n",
    "#     # TODO: Possibly need to change\n",
    "#     pred_classes = logits\n",
    "# #     pred_classes = tf.argmax(logits, axis=1)\n",
    "# #     pred_probas = tf.nn.softmax(logits)\n",
    "#     pred_probas = tf.nn.sigmoid(logits)\n",
    "    \n",
    "#     # If prediction mode, early return\n",
    "#     if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "#         return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "    \n",
    "#     print(logits.shape)\n",
    "# #     print(resizedLogits.shape)\n",
    "#     print(labels.shape)\n",
    "#     print(pred_classes.shape)\n",
    "        \n",
    "#     # Define loss and optimizer\n",
    "# #     loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "# #         logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "#     loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "#         logits=logits, labels=labels))\n",
    "#     optimizer = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE)\n",
    "#     train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    \n",
    "#     # Evaluate the accuracy of the model\n",
    "# #     acc_op = tf.metrics.accuracy(labels=tf.argmax(labels, axis=1), predictions=pred_classes)\n",
    "#     acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "    \n",
    "#     # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "#     # the different ops for training, evaluating, ...\n",
    "#     estim_specs = tf.estimator.EstimatorSpec(\n",
    "#       mode=mode,\n",
    "#       predictions=pred_classes,\n",
    "#       loss=loss_op,\n",
    "#       train_op=train_op,\n",
    "#       eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "#     return estim_specs\n",
    "\n",
    "# Define the model function (following TF Estimator Template)\n",
    "def modelFunc(features, labels, mode):\n",
    "    # Build the neural network\n",
    "    logits = network(features, mode)\n",
    "    \n",
    "#     resizedLogits = tf.reshape(logits, shape=[-1, MAX_SIZE * MAX_SIZE, 1])\n",
    "    \n",
    "    # Predictions\n",
    "    # TODO: Possibly need to change\n",
    "#     pred_classes = logits\n",
    "    pred_classes = tf.map_fn(convertPredToRank, logits)\n",
    "#     pred_classes = tf.argmax(logits, axis=1)\n",
    "#     pred_probas = tf.nn.softmax(logits)\n",
    "    \n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "#     loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "#         logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "#     loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "#         logits=logits, labels=labels))\n",
    "#     loss_op = tf.reduce_mean(loss(labels, logits))\n",
    "    loss_op = tf.reduce_mean(listNetLoss(labels, logits))\n",
    "#     loss_map = tf.map_fn(lambda x: listMLE2(x[0], x[1]), (labels, pred_classes), dtype=tf.float64)\n",
    "#     print(labels.get_shape()[0])\n",
    "#     labels_length = tf.shape(labels)[0]\n",
    "#     loss_op = tf.reduce_mean(listMLE2Loss(labels, logits, labels_length, tf.cast(labels_length, dtype=tf.float32)))\n",
    "#     optimizer = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE)\n",
    "    optimizer = tf.contrib.opt.NadamOptimizer(learning_rate=LEARNING_RATE)\n",
    "#     optimizer = tf.train.AdamOptimizer()\n",
    "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # Evaluate the accuracy of the model\n",
    "#     acc_op = tf.metrics.accuracy(labels=tf.argmax(labels, axis=1), predictions=pred_classes)\n",
    "#     acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "    ndcg_map = tf.map_fn(lambda x: ndcg(x[0], x[1]), (labels, pred_classes), dtype=tf.float32)\n",
    "    ndcg_op = tf.metrics.mean(ndcg_map)\n",
    "    top1_map = tf.map_fn(lambda x: top1Match(x[0], x[1]), (labels, pred_classes), dtype=tf.float32)\n",
    "    top1_op = tf.metrics.mean(top1_map)\n",
    "    top2_map = tf.map_fn(lambda x: top2Match(x[0], x[1]), (labels, pred_classes), dtype=tf.float32)\n",
    "    top2_op = tf.metrics.mean(top2_map)\n",
    "    spearman_map = tf.map_fn(lambda x: boundedSpearman(x[0], x[1]), (labels, pred_classes), dtype=tf.float32)\n",
    "    acc_op = tf.metrics.mean(spearman_map)\n",
    "    \n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=pred_classes,\n",
    "      loss=loss_op,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops={'accuracy': acc_op, 'ndcg': ndcg_op, 'top1Classification': top1_op, 'top2Classification': top2_op})\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpaa3ok_yc\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7e887fd390>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 10000, '_save_checkpoints_secs': 600, '_log_step_count_steps': 10000, '_session_config': , '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmpaa3ok_yc'}\n"
     ]
    }
   ],
   "source": [
    "# Build the Estimator\n",
    "config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "model = tf.estimator.Estimator(modelFunc, config=tf.contrib.learn.RunConfig(session_config=config, save_summary_steps=10000, log_step_count_steps=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainResults = []\n",
    "validResults = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.321966, step = 1\n",
      "INFO:tensorflow:loss = 0.308329, step = 101 (198.872 sec)\n",
      "INFO:tensorflow:loss = 0.306319, step = 201 (197.846 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 301 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.295496, step = 301 (202.137 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 400 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.299042.\n",
      "Evaluating Train\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-13:49:03\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-400\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-13:52:17\n",
      "INFO:tensorflow:Saving dict for global step 400: accuracy = 0.430317, global_step = 400, loss = 0.298216, ndcg = 0.862179, top1Classification = 0.345708, top2Classification = 0.998453\n",
      "Evaluating Valid\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-13:52:20\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-400\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-13:53:25\n",
      "INFO:tensorflow:Saving dict for global step 400: accuracy = 0.578306, global_step = 400, loss = 0.321358, ndcg = 0.884578, top1Classification = 0.169374, top2Classification = 0.953596\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-400\n",
      "INFO:tensorflow:Saving checkpoints for 401 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.296516, step = 401\n",
      "INFO:tensorflow:loss = 0.292926, step = 501 (195.722 sec)\n",
      "INFO:tensorflow:loss = 0.299143, step = 601 (197.139 sec)\n",
      "INFO:tensorflow:loss = 0.3062, step = 701 (198.047 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 705 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 800 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.288155.\n",
      "Evaluating Train\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-14:06:50\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-800\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-14:10:06\n",
      "INFO:tensorflow:Saving dict for global step 800: accuracy = 0.464308, global_step = 800, loss = 0.289716, ndcg = 0.87932, top1Classification = 0.46017, top2Classification = 0.977572\n",
      "Evaluating Valid\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-14:10:08\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-800\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-14:11:13\n",
      "INFO:tensorflow:Saving dict for global step 800: accuracy = 0.559861, global_step = 800, loss = 0.33303, ndcg = 0.882436, top1Classification = 0.243619, top2Classification = 0.935035\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-800\n",
      "INFO:tensorflow:Saving checkpoints for 801 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.292521, step = 801\n",
      "INFO:tensorflow:loss = 0.276573, step = 901 (197.265 sec)\n",
      "INFO:tensorflow:loss = 0.279348, step = 1001 (196.520 sec)\n",
      "INFO:tensorflow:loss = 0.279811, step = 1101 (194.573 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1106 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 1200 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.287872.\n",
      "Evaluating Train\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-14:24:35\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-1200\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-14:27:59\n",
      "INFO:tensorflow:Saving dict for global step 1200: accuracy = 0.467054, global_step = 1200, loss = 0.278727, ndcg = 0.87955, top1Classification = 0.340294, top2Classification = 0.802784\n",
      "Evaluating Valid\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-14:28:01\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-1200\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-14:29:09\n",
      "INFO:tensorflow:Saving dict for global step 1200: accuracy = 0.567981, global_step = 1200, loss = 0.335268, ndcg = 0.88496, top1Classification = 0.194896, top2Classification = 0.802784\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-1200\n",
      "INFO:tensorflow:Saving checkpoints for 1201 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.274892, step = 1201\n",
      "INFO:tensorflow:loss = 0.282122, step = 1301 (190.244 sec)\n",
      "INFO:tensorflow:loss = 0.276518, step = 1401 (191.464 sec)\n",
      "INFO:tensorflow:loss = 0.277552, step = 1501 (191.161 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1514 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 1600 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.276737.\n",
      "Evaluating Train\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-14:42:08\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-1600\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-14:45:25\n",
      "INFO:tensorflow:Saving dict for global step 1600: accuracy = 0.507424, global_step = 1600, loss = 0.271717, ndcg = 0.888334, top1Classification = 0.261408, top2Classification = 0.711524\n",
      "Evaluating Valid\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-14:45:27\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-1600\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-14:46:35\n",
      "INFO:tensorflow:Saving dict for global step 1600: accuracy = 0.57297, global_step = 1600, loss = 0.336871, ndcg = 0.882878, top1Classification = 0.169374, top2Classification = 0.647332\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-1600\n",
      "INFO:tensorflow:Saving checkpoints for 1601 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.264947, step = 1601\n",
      "INFO:tensorflow:loss = 0.27159, step = 1701 (196.312 sec)\n",
      "INFO:tensorflow:loss = 0.269559, step = 1801 (196.337 sec)\n",
      "INFO:tensorflow:loss = 0.261766, step = 1901 (195.668 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1906 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.257557.\n",
      "Evaluating Train\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-14:59:55\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-15:03:12\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.524903, global_step = 2000, loss = 0.257521, ndcg = 0.892181, top1Classification = 0.300851, top2Classification = 0.798144\n",
      "Evaluating Valid\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-15:03:14\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-15:04:19\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.550696, global_step = 2000, loss = 0.348461, ndcg = 0.875393, top1Classification = 0.190255, top2Classification = 0.682135\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-2000\n",
      "INFO:tensorflow:Saving checkpoints for 2001 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.253521, step = 2001\n",
      "INFO:tensorflow:loss = 0.255173, step = 2101 (196.378 sec)\n",
      "INFO:tensorflow:loss = 0.257847, step = 2201 (194.769 sec)\n",
      "INFO:tensorflow:loss = 0.250416, step = 2301 (195.499 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2307 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 2400 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.248541.\n",
      "Evaluating Train\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-15:17:40\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-04-21-15:21:04\n",
      "INFO:tensorflow:Saving dict for global step 2400: accuracy = 0.528577, global_step = 2400, loss = 0.248843, ndcg = 0.892237, top1Classification = 0.277649, top2Classification = 0.766435\n",
      "Evaluating Valid\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-15:21:07\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-2400\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-15:22:16\n",
      "INFO:tensorflow:Saving dict for global step 2400: accuracy = 0.552784, global_step = 2400, loss = 0.357851, ndcg = 0.876419, top1Classification = 0.194896, top2Classification = 0.693735\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-2400\n",
      "INFO:tensorflow:Saving checkpoints for 2401 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.243926, step = 2401\n",
      "INFO:tensorflow:loss = 0.245007, step = 2501 (196.663 sec)\n",
      "INFO:tensorflow:loss = 0.246307, step = 2601 (194.824 sec)\n",
      "INFO:tensorflow:loss = 0.247376, step = 2701 (196.386 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2706 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 2800 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.25016.\n",
      "Evaluating Train\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-15:35:33\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-2800\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-15:38:48\n",
      "INFO:tensorflow:Saving dict for global step 2800: accuracy = 0.521036, global_step = 2800, loss = 0.242048, ndcg = 0.891255, top1Classification = 0.277649, top2Classification = 0.75406\n",
      "Evaluating Valid\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-15:38:50\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-2800\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-15:39:56\n",
      "INFO:tensorflow:Saving dict for global step 2800: accuracy = 0.544896, global_step = 2800, loss = 0.36567, ndcg = 0.872684, top1Classification = 0.176334, top2Classification = 0.682135\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-2800\n",
      "INFO:tensorflow:Saving checkpoints for 2801 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.243434, step = 2801\n",
      "INFO:tensorflow:loss = 0.238905, step = 2901 (198.081 sec)\n",
      "INFO:tensorflow:loss = 0.23824, step = 3001 (197.802 sec)\n",
      "INFO:tensorflow:loss = 0.236569, step = 3101 (196.831 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3104 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 3200 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.237387.\n",
      "Evaluating Train\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-15:53:24\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-3200\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-15:57:56\n",
      "INFO:tensorflow:Saving dict for global step 3200: accuracy = 0.538167, global_step = 3200, loss = 0.377116, ndcg = 0.871403, top1Classification = 0.220418, top2Classification = 0.726218\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-3200\n",
      "INFO:tensorflow:Saving checkpoints for 3201 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.229897, step = 3201\n",
      "INFO:tensorflow:loss = 0.236512, step = 3301 (197.596 sec)\n",
      "INFO:tensorflow:loss = 0.229051, step = 3401 (193.053 sec)\n",
      "INFO:tensorflow:loss = 0.228908, step = 3501 (192.548 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3508 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 3600 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.226234.\n",
      "Evaluating Train\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-16:11:11\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-3600\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-16:14:31\n",
      "INFO:tensorflow:Saving dict for global step 3600: accuracy = 0.479892, global_step = 3600, loss = 0.228436, ndcg = 0.876476, top1Classification = 0.322506, top2Classification = 0.753287\n",
      "Evaluating Valid\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-16:14:33\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-3600\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-16:15:40\n",
      "INFO:tensorflow:Saving dict for global step 3600: accuracy = 0.54768, global_step = 3600, loss = 0.379897, ndcg = 0.875023, top1Classification = 0.185615, top2Classification = 0.672854\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-3600\n",
      "INFO:tensorflow:Saving checkpoints for 3601 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.231251, step = 3601\n",
      "INFO:tensorflow:loss = 0.225746, step = 3701 (195.059 sec)\n",
      "INFO:tensorflow:loss = 0.223984, step = 3801 (195.928 sec)\n",
      "INFO:tensorflow:loss = 0.22208, step = 3901 (194.604 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3908 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.225958.\n",
      "Evaluating Train\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-16:28:58\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-4000\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-16:32:17\n",
      "INFO:tensorflow:Saving dict for global step 4000: accuracy = 0.480859, global_step = 4000, loss = 0.222971, ndcg = 0.878515, top1Classification = 0.33256, top2Classification = 0.768755\n",
      "Evaluating Valid\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-16:32:19\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-4000\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-16:33:27\n",
      "INFO:tensorflow:Saving dict for global step 4000: accuracy = 0.572042, global_step = 4000, loss = 0.391606, ndcg = 0.882647, top1Classification = 0.222738, top2Classification = 0.703016\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-4000\n",
      "INFO:tensorflow:Saving checkpoints for 4001 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.222873, step = 4001\n",
      "INFO:tensorflow:loss = 0.224608, step = 4101 (199.380 sec)\n",
      "INFO:tensorflow:loss = 0.224771, step = 4201 (202.454 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4300 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.222335, step = 4301 (201.418 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4400 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.218799.\n",
      "Evaluating Train\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-16:47:02\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-4400\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-16:50:23\n",
      "INFO:tensorflow:Saving dict for global step 4400: accuracy = 0.481168, global_step = 4400, loss = 0.2205, ndcg = 0.879714, top1Classification = 0.324053, top2Classification = 0.735499\n",
      "Evaluating Valid\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-16:50:25\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-4400\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-16:51:32\n",
      "INFO:tensorflow:Saving dict for global step 4400: accuracy = 0.534455, global_step = 4400, loss = 0.391739, ndcg = 0.873374, top1Classification = 0.185615, top2Classification = 0.698376\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-4400\n",
      "INFO:tensorflow:Saving checkpoints for 4401 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.220293, step = 4401\n",
      "INFO:tensorflow:loss = 0.222562, step = 4501 (194.468 sec)\n",
      "INFO:tensorflow:loss = 0.218132, step = 4601 (199.822 sec)\n",
      "INFO:tensorflow:loss = 0.217513, step = 4701 (195.518 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 4705 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 4800 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.219508.\n",
      "Evaluating Train\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-17:04:55\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-4800\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-17:08:15\n",
      "INFO:tensorflow:Saving dict for global step 4800: accuracy = 0.462762, global_step = 4800, loss = 0.217118, ndcg = 0.871075, top1Classification = 0.315545, top2Classification = 0.7471\n",
      "Evaluating Valid\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-17:08:17\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-4800\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-17:09:24\n",
      "INFO:tensorflow:Saving dict for global step 4800: accuracy = 0.524478, global_step = 4800, loss = 0.402796, ndcg = 0.869251, top1Classification = 0.204176, top2Classification = 0.761021\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-4800\n",
      "INFO:tensorflow:Saving checkpoints for 4801 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.217373, step = 4801\n",
      "INFO:tensorflow:loss = 0.217636, step = 4901 (191.576 sec)\n",
      "INFO:tensorflow:loss = 0.217068, step = 5001 (191.915 sec)\n",
      "INFO:tensorflow:loss = 0.21624, step = 5101 (191.032 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5113 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 5200 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.215086.\n",
      "Evaluating Train\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-17:22:26\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-5200\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-17:25:47\n",
      "INFO:tensorflow:Saving dict for global step 5200: accuracy = 0.454332, global_step = 5200, loss = 0.214921, ndcg = 0.869473, top1Classification = 0.310131, top2Classification = 0.720031\n",
      "Evaluating Valid\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-17:25:49\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-5200\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-17:26:54\n",
      "INFO:tensorflow:Saving dict for global step 5200: accuracy = 0.521694, global_step = 5200, loss = 0.401089, ndcg = 0.868146, top1Classification = 0.167053, top2Classification = 0.721578\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-5200\n",
      "INFO:tensorflow:Saving checkpoints for 5201 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.214339, step = 5201\n",
      "INFO:tensorflow:loss = 0.216616, step = 5301 (195.333 sec)\n",
      "INFO:tensorflow:loss = 0.213458, step = 5401 (195.785 sec)\n",
      "INFO:tensorflow:loss = 0.212496, step = 5501 (198.387 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5505 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 5600 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.216448.\n",
      "Evaluating Train\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-17:40:15\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-5600\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-17:43:32\n",
      "INFO:tensorflow:Saving dict for global step 5600: accuracy = 0.448106, global_step = 5600, loss = 0.21498, ndcg = 0.864301, top1Classification = 0.311678, top2Classification = 0.738592\n",
      "Evaluating Valid\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-17:43:34\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-5600\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-17:44:40\n",
      "INFO:tensorflow:Saving dict for global step 5600: accuracy = 0.541531, global_step = 5600, loss = 0.407205, ndcg = 0.874057, top1Classification = 0.218097, top2Classification = 0.7471\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-5600\n",
      "INFO:tensorflow:Saving checkpoints for 5601 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.215509, step = 5601\n",
      "INFO:tensorflow:loss = 0.213228, step = 5701 (193.632 sec)\n",
      "INFO:tensorflow:loss = 0.214559, step = 5801 (192.085 sec)\n",
      "INFO:tensorflow:loss = 0.218654, step = 5901 (194.004 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5910 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.216822.\n",
      "Evaluating Train\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-17:57:48\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-6000\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-18:01:10\n",
      "INFO:tensorflow:Saving dict for global step 6000: accuracy = 0.454757, global_step = 6000, loss = 0.215963, ndcg = 0.868555, top1Classification = 0.308585, top2Classification = 0.720031\n",
      "Evaluating Valid\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-18:01:12\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-6000\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-18:02:21\n",
      "INFO:tensorflow:Saving dict for global step 6000: accuracy = 0.549884, global_step = 6000, loss = 0.394561, ndcg = 0.877965, top1Classification = 0.185615, top2Classification = 0.705336\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-6000\n",
      "INFO:tensorflow:Saving checkpoints for 6001 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.215347, step = 6001\n",
      "INFO:tensorflow:loss = 0.221043, step = 6101 (199.285 sec)\n",
      "INFO:tensorflow:loss = 0.217597, step = 6201 (197.987 sec)\n",
      "INFO:tensorflow:loss = 0.215318, step = 6301 (197.291 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6303 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 6400 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.213689.\n",
      "Evaluating Train\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-18:15:48\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-6400\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-18:19:09\n",
      "INFO:tensorflow:Saving dict for global step 6400: accuracy = 0.454254, global_step = 6400, loss = 0.212414, ndcg = 0.867167, top1Classification = 0.307038, top2Classification = 0.724671\n",
      "Evaluating Valid\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-18:19:11\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-6400\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-18:20:15\n",
      "INFO:tensorflow:Saving dict for global step 6400: accuracy = 0.534223, global_step = 6400, loss = 0.407681, ndcg = 0.871965, top1Classification = 0.197216, top2Classification = 0.712297\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-6400\n",
      "INFO:tensorflow:Saving checkpoints for 6401 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.212872, step = 6401\n",
      "INFO:tensorflow:loss = 0.212385, step = 6501 (199.537 sec)\n",
      "INFO:tensorflow:loss = 0.210611, step = 6601 (196.471 sec)\n",
      "INFO:tensorflow:loss = 0.213467, step = 6701 (198.781 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6703 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 6800 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.212251.\n",
      "Evaluating Train\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-18:33:43\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-6800\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-18:37:00\n",
      "INFO:tensorflow:Saving dict for global step 6800: accuracy = 0.451392, global_step = 6800, loss = 0.211986, ndcg = 0.865328, top1Classification = 0.305491, top2Classification = 0.718484\n",
      "Evaluating Valid\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-04-21-18:37:02\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-6800\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-18:38:09\n",
      "INFO:tensorflow:Saving dict for global step 6800: accuracy = 0.541995, global_step = 6800, loss = 0.398773, ndcg = 0.874742, top1Classification = 0.197216, top2Classification = 0.723898\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-6800\n",
      "INFO:tensorflow:Saving checkpoints for 6801 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.211477, step = 6801\n",
      "INFO:tensorflow:loss = 0.211156, step = 6901 (195.860 sec)\n",
      "INFO:tensorflow:loss = 0.211272, step = 7001 (200.328 sec)\n",
      "INFO:tensorflow:loss = 0.211349, step = 7101 (197.646 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7103 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 7200 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.209823.\n",
      "Evaluating Train\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-18:51:37\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-7200\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-18:54:55\n",
      "INFO:tensorflow:Saving dict for global step 7200: accuracy = 0.448376, global_step = 7200, loss = 0.209498, ndcg = 0.865603, top1Classification = 0.303944, top2Classification = 0.716164\n",
      "Evaluating Valid\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-18:54:57\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-7200\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-18:56:04\n",
      "INFO:tensorflow:Saving dict for global step 7200: accuracy = 0.536543, global_step = 7200, loss = 0.41158, ndcg = 0.872832, top1Classification = 0.197216, top2Classification = 0.716937\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-7200\n",
      "INFO:tensorflow:Saving checkpoints for 7201 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.209412, step = 7201\n",
      "INFO:tensorflow:loss = 0.207951, step = 7301 (192.102 sec)\n",
      "INFO:tensorflow:loss = 0.209015, step = 7401 (192.271 sec)\n",
      "INFO:tensorflow:loss = 0.208094, step = 7501 (194.151 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7511 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 7600 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.209734.\n",
      "Evaluating Train\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-19:09:14\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-7600\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-19:12:26\n",
      "INFO:tensorflow:Saving dict for global step 7600: accuracy = 0.445863, global_step = 7600, loss = 0.208835, ndcg = 0.863102, top1Classification = 0.303944, top2Classification = 0.70843\n",
      "Evaluating Valid\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-19:12:28\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-7600\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-19:13:33\n",
      "INFO:tensorflow:Saving dict for global step 7600: accuracy = 0.537355, global_step = 7600, loss = 0.412486, ndcg = 0.874163, top1Classification = 0.211137, top2Classification = 0.726218\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-7600\n",
      "INFO:tensorflow:Saving checkpoints for 7601 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.209886, step = 7601\n",
      "INFO:tensorflow:loss = 0.208869, step = 7701 (192.468 sec)\n",
      "INFO:tensorflow:loss = 0.208038, step = 7801 (188.884 sec)\n",
      "INFO:tensorflow:loss = 0.208949, step = 7901 (189.163 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7915 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.207819.\n",
      "Evaluating Train\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-19:26:35\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-8000\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-19:29:53\n",
      "INFO:tensorflow:Saving dict for global step 8000: accuracy = 0.448415, global_step = 8000, loss = 0.207757, ndcg = 0.863019, top1Classification = 0.303944, top2Classification = 0.704563\n",
      "Evaluating Valid\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-21-19:29:55\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-8000\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-21-19:31:00\n",
      "INFO:tensorflow:Saving dict for global step 8000: accuracy = 0.537007, global_step = 8000, loss = 0.413184, ndcg = 0.87361, top1Classification = 0.187935, top2Classification = 0.716937\n",
      "(?, 300, 300)\n",
      "(?, 300, 300, 1)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpaa3ok_yc/model.ckpt-8000\n",
      "INFO:tensorflow:Saving checkpoints for 8001 into /tmp/tmpaa3ok_yc/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.208901, step = 8001\n",
      "INFO:tensorflow:loss = 0.20677, step = 8101 (192.277 sec)\n",
      "INFO:tensorflow:loss = 0.207422, step = 8201 (192.299 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d0af0113d8d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputFunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating Train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps)\u001b[0m\n\u001b[1;32m    239\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    516\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    860\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    970\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainFunc = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"input\": inputsTrain.astype(np.float32), \"length\": lengthsTrain}, y=outputsTrainUnnorm.astype(np.float32),\n",
    "    batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "validFunc = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"input\": inputsValid.astype(np.float32), \"length\": lengthsValid}, y=outputsValidUnnorm.astype(np.float32),\n",
    "    batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "for i in range(0, 100):\n",
    "    model.train(inputFunc, steps=400)\n",
    "    \n",
    "    print(\"Evaluating Train\")\n",
    "    accuracy = model.evaluate(trainFunc)\n",
    "    trainResults.append(accuracy)\n",
    "    \n",
    "    print(\"Evaluating Valid\")\n",
    "    accuracy = model.evaluate(validFunc)\n",
    "    validResults.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.47911829,\n",
       "  'global_step': 1011,\n",
       "  'loss': 0.38012153,\n",
       "  'ndcg': 0.85750318,\n",
       "  'top1Classification': 0.14153132,\n",
       "  'top2Classification': 0.675174},\n",
       " {'accuracy': 0.46972162,\n",
       "  'global_step': 2022,\n",
       "  'loss': 0.39480475,\n",
       "  'ndcg': 0.85565573,\n",
       "  'top1Classification': 0.13921113,\n",
       "  'top2Classification': 0.63109046},\n",
       " {'accuracy': 0.46600926,\n",
       "  'global_step': 3033,\n",
       "  'loss': 0.39247605,\n",
       "  'ndcg': 0.8527562,\n",
       "  'top1Classification': 0.1438515,\n",
       "  'top2Classification': 0.66589326},\n",
       " {'accuracy': 0.4575406,\n",
       "  'global_step': 4044,\n",
       "  'loss': 0.39723518,\n",
       "  'ndcg': 0.85106581,\n",
       "  'top1Classification': 0.13689095,\n",
       "  'top2Classification': 0.6403712},\n",
       " {'accuracy': 0.47169375,\n",
       "  'global_step': 5055,\n",
       "  'loss': 0.39897355,\n",
       "  'ndcg': 0.85377109,\n",
       "  'top1Classification': 0.13689095,\n",
       "  'top2Classification': 0.68213457},\n",
       " {'accuracy': 0.461833,\n",
       "  'global_step': 6066,\n",
       "  'loss': 0.39418501,\n",
       "  'ndcg': 0.85060596,\n",
       "  'top1Classification': 0.12761021,\n",
       "  'top2Classification': 0.66357309},\n",
       " {'accuracy': 0.47575408,\n",
       "  'global_step': 7077,\n",
       "  'loss': 0.39505532,\n",
       "  'ndcg': 0.85417473,\n",
       "  'top1Classification': 0.11832947,\n",
       "  'top2Classification': 0.66357309},\n",
       " {'accuracy': 0.48457077,\n",
       "  'global_step': 8088,\n",
       "  'loss': 0.39398947,\n",
       "  'ndcg': 0.85920292,\n",
       "  'top1Classification': 0.13921113,\n",
       "  'top2Classification': 0.675174}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-04-01-13:09:25\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpg3jck0j2/model.ckpt-101100\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-01-13:09:27\n",
      "INFO:tensorflow:Saving dict for global step 101100: accuracy = 0.534803, global_step = 101100, loss = 0.317587, ndcg = 0.871996, top1Classification = 0.577726, top2Classification = 0.958237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.53480279,\n",
       " 'global_step': 101100,\n",
       " 'loss': 0.31758687,\n",
       " 'ndcg': 0.87199575,\n",
       " 'top1Classification': 0.57772624,\n",
       " 'top2Classification': 0.95823663}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "validFunc = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"input\": inputsValid.astype(np.float32), \"length\": lengthsValid}, y=outputsValidUnnorm.astype(np.float32),\n",
    "    batch_size=BATCH_SIZE, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "model.evaluate(validFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmpg3jck0j2/model.ckpt-101100\n"
     ]
    }
   ],
   "source": [
    "predictions = list(model.predict(validFunc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'[ 2.  1.  3.  4.  0.]': 431})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(list(map(str, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'[0 1 2 3 4]': 4,\n",
       "         '[0 1 2 4 3]': 3,\n",
       "         '[0 1 4 2 3]': 1,\n",
       "         '[0 2 1 3 4]': 1,\n",
       "         '[0 2 1 4 3]': 100,\n",
       "         '[0 2 3 4 1]': 4,\n",
       "         '[0 2 4 1 3]': 196,\n",
       "         '[0 2 4 3 1]': 22,\n",
       "         '[0 4 2 1 3]': 1,\n",
       "         '[0 4 2 3 1]': 1,\n",
       "         '[1 2 0 4 3]': 2,\n",
       "         '[1 2 3 0 4]': 2,\n",
       "         '[1 2 3 4 0]': 1,\n",
       "         '[1 2 4 0 3]': 4,\n",
       "         '[1 3 2 0 4]': 1,\n",
       "         '[2 0 1 3 4]': 5,\n",
       "         '[2 0 1 4 3]': 198,\n",
       "         '[2 0 3 1 4]': 3,\n",
       "         '[2 0 3 4 1]': 12,\n",
       "         '[2 0 4 1 3]': 198,\n",
       "         '[2 0 4 3 1]': 195,\n",
       "         '[2 1 0 4 3]': 4,\n",
       "         '[2 1 3 4 0]': 6,\n",
       "         '[2 1 4 0 3]': 20,\n",
       "         '[2 1 4 3 0]': 5,\n",
       "         '[2 3 0 4 1]': 2,\n",
       "         '[2 3 1 4 0]': 4,\n",
       "         '[2 3 4 0 1]': 5,\n",
       "         '[2 3 4 1 0]': 9,\n",
       "         '[2 4 0 1 3]': 195,\n",
       "         '[2 4 0 3 1]': 177,\n",
       "         '[2 4 1 0 3]': 68,\n",
       "         '[2 4 1 3 0]': 101,\n",
       "         '[2 4 3 0 1]': 42,\n",
       "         '[2 4 3 1 0]': 49,\n",
       "         '[3 4 1 2 0]': 1,\n",
       "         '[4 0 1 2 3]': 1,\n",
       "         '[4 0 2 1 3]': 10,\n",
       "         '[4 0 2 3 1]': 3,\n",
       "         '[4 1 2 0 3]': 2,\n",
       "         '[4 1 2 3 0]': 5,\n",
       "         '[4 2 0 1 3]': 34,\n",
       "         '[4 2 0 3 1]': 6,\n",
       "         '[4 2 1 0 3]': 8,\n",
       "         '[4 2 1 3 0]': 3,\n",
       "         '[4 2 3 1 0]': 8,\n",
       "         '[4 3 1 2 0]': 1,\n",
       "         '[4 3 2 0 1]': 1})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(list(map(str, indexRankings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.43051046,\n",
       " 'global_step': 404100,\n",
       " 'loss': 0.21140459,\n",
       " 'ndcg': 0.84055918,\n",
       " 'top1Classification': 0.31090486,\n",
       " 'top2Classification': 0.71616393}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainResults[len(trainResults) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.53317863,\n",
       " 'global_step': 404100,\n",
       " 'loss': 0.4090046,\n",
       " 'ndcg': 0.8764475,\n",
       " 'top1Classification': 0.15777262,\n",
       " 'top2Classification': 0.77030164}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validResults[len(validResults) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
