{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/features/analysis.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "MAX_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 39 rows due to None values\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NA\n",
    "rowsBefore = df.shape[0]\n",
    "df = df.dropna()\n",
    "print(\"Dropped %d rows due to None values\" % (rowsBefore - df.shape[0]))\n",
    "\n",
    "# Filter instances larger than MAX_SIZE\n",
    "df = df.loc[df[\"simpleFeatures.numberVertices\"] <= MAX_SIZE]\n",
    "\n",
    "minCostIndices = df[[\"heuristics.tabuCosts\", \"heuristics.simulatedAnnealingCosts\", \"heuristics.graspCosts\", \"heuristics.geneticCosts\", \"heuristics.antColonyCosts\"]].idxmin(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad matrices\n",
    "paddedArray = np.zeros((len(df), MAX_SIZE * MAX_SIZE))\n",
    "i = 0\n",
    "for index, row in df.iterrows():\n",
    "    zeroed = np.zeros((MAX_SIZE, MAX_SIZE))\n",
    "    costs = row[\"costs\"]\n",
    "    zeroed[:costs.shape[0],:costs.shape[1]] = costs\n",
    "    \n",
    "    paddedArray[i] = scale(zeroed.astype('float64'), axis=1).reshape(MAX_SIZE * MAX_SIZE)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = paddedArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "intLabels = LabelEncoder().fit_transform(minCostIndices).reshape(-1, 1)\n",
    "# 5 values for 5 different heuristics\n",
    "outputs = OneHotEncoder(sparse=False, n_values=5).fit_transform(intLabels)\n",
    "\n",
    "inputs = df\n",
    "\n",
    "size = df.shape[0]\n",
    "# Test data is separated in cleaning stage\n",
    "trainSize = int(size * 0.75)\n",
    "validSize = size - trainSize\n",
    "\n",
    "inputsTrain = inputs[0:trainSize]\n",
    "outputsTrain = outputs[0:trainSize]\n",
    "intLabelsTrain = intLabels[0:trainSize]\n",
    "\n",
    "inputsValid = inputs[trainSize:]\n",
    "outputsValid = outputs[trainSize:]\n",
    "intLabelsValid = intLabels[trainSize:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_count = 0\n",
    "\n",
    "def minibatch(batchSize, n, input_data, output_data):\n",
    "    input_batches = np.empty((math.ceil(n/batchSize), batchSize) + input_data.shape[1:])\n",
    "    output_batches = np.empty((math.ceil(n/batchSize), batchSize) + output_data.shape[1:])\n",
    "    \n",
    "    global epoch_count\n",
    "    epoch_count += 1\n",
    "    indexes = np.random.permutation(n)\n",
    "    i = 0\n",
    "    batch_i = 0\n",
    "    input_array = np.zeros((batchSize,) + input_data.shape[1:])\n",
    "    output_array = np.zeros((batchSize,) + output_data.shape[1:])\n",
    "    for index in indexes:\n",
    "        input_array[i] = input_data[index]\n",
    "        output_array[i] = output_data[index]\n",
    "        i += 1\n",
    "\n",
    "        if i >= batchSize:\n",
    "            input_batches[batch_i] = input_array\n",
    "            output_batches[batch_i] = output_array\n",
    "            i = 0\n",
    "            batch_i += 1\n",
    "    \n",
    "    if(n % batchSize != 0):\n",
    "        input_array[i:] = input_data[0:batchSize - i]\n",
    "        output_array[i:] = output_data[0:batchSize - i]\n",
    "        input_batches[batch_i] = input_array\n",
    "        output_batches[batch_i] = output_array\n",
    "    \n",
    "    return (input_batches, output_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "\n",
    "N1 = trainSize\n",
    "FEATURE_COUNT = df.shape[1]\n",
    "LABEL_COUNT = 5\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "NODES1 = 256\n",
    "NODES2 = 128\n",
    "\n",
    "ALPHA = 0.08\n",
    "\n",
    "BATCH_SIZE = 30\n",
    "\n",
    "STD = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Tensorflow\n",
    "\n",
    "# Constants\n",
    "x_train_full = tf.constant(inputsTrain, dtype='float32', shape=[trainSize, FEATURE_COUNT])\n",
    "y_train_full = tf.constant(outputsTrain, dtype='float32', shape=[trainSize, LABEL_COUNT])\n",
    "\n",
    "x_valid_full = tf.constant(inputsValid, dtype='float32', shape=[validSize, FEATURE_COUNT])\n",
    "y_valid_full = tf.constant(outputsValid, dtype='float32', shape=[validSize, LABEL_COUNT])\n",
    "\n",
    "x_train = tf.placeholder(tf.float32, [BATCH_SIZE, FEATURE_COUNT])\n",
    "y_train = tf.placeholder(tf.float32, [BATCH_SIZE, LABEL_COUNT])\n",
    "\n",
    "# Variables\n",
    "W_input = tf.Variable(tf.truncated_normal([FEATURE_COUNT, NODES1], stddev=STD, seed = 0))\n",
    "b_input = tf.Variable(tf.truncated_normal([1, NODES1], stddev=STD, seed = 0))\n",
    "\n",
    "W_hidden = tf.Variable(tf.truncated_normal([NODES1, NODES2], stddev=STD, seed = 0))\n",
    "b_hidden = tf.Variable(tf.truncated_normal([1, NODES2], stddev=STD, seed = 0))\n",
    "\n",
    "W_hidden2 = tf.Variable(tf.truncated_normal([NODES2, LABEL_COUNT], stddev=STD, seed = 0))\n",
    "b_hidden2 = tf.Variable(tf.truncated_normal([1, LABEL_COUNT], stddev=STD, seed = 0))\n",
    "\n",
    "# Optimization\n",
    "input_layer = tf.nn.relu(tf.matmul(x_train, W_input) + b_input)\n",
    "\n",
    "hidden_layer = tf.nn.relu(tf.matmul(input_layer, W_hidden) + b_hidden)\n",
    "hidden2_layer = tf.matmul(hidden_layer, W_hidden2) + b_hidden2\n",
    "\n",
    "logits_train_full = tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(x_train_full, W_input) + b_input), W_hidden) + b_hidden), W_hidden2) + b_hidden2\n",
    "logits_valid_full = tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(x_valid_full, W_input) + b_input), W_hidden) + b_hidden), W_hidden2) + b_hidden2\n",
    "\n",
    "L2 = tf.reduce_mean(ALPHA * (tf.nn.l2_loss(W_input) + tf.nn.l2_loss(W_hidden) + tf.nn.l2_loss(W_hidden2)))\n",
    "\n",
    "CE = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = hidden2_layer, labels = y_train) + ALPHA * (tf.nn.l2_loss(W_input) + tf.nn.l2_loss(W_hidden) + tf.nn.l2_loss(W_hidden2)))\n",
    "\n",
    "CE_train_full = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits_train_full, labels = y_train_full) + ALPHA * (tf.nn.l2_loss(W_input) + tf.nn.l2_loss(W_hidden) + tf.nn.l2_loss(W_hidden2)))\n",
    "CE_valid_full = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits_valid_full, labels = y_valid_full) + ALPHA * (tf.nn.l2_loss(W_input) + tf.nn.l2_loss(W_hidden) + tf.nn.l2_loss(W_hidden2)))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer().minimize(CE)\n",
    "\n",
    "y_pred_train = tf.nn.softmax(logits_train_full)\n",
    "y_pred_valid = tf.nn.softmax(logits_valid_full)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1114), Dimension(5)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1114), Dimension(5)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TensorFlow\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printStats():\n",
    "    (ce_train,ce_valid,p_train,p_valid,l2) = sess.run([CE_train_full, CE_valid_full, y_pred_train, y_pred_valid, L2])\n",
    "    labels_train_pred = oneHotArray[p_train.argmax(axis=1)]\n",
    "    labels_valid_pred = oneHotArray[p_valid.argmax(axis=1)]\n",
    "    error_train = 1 - accuracy_score(intLabelsTrain, labels_train_pred)\n",
    "    error_valid = 1 - accuracy_score(intLabelsValid, labels_valid_pred)\n",
    "    total_compute_time = (time.time() - t_start)/60\n",
    "    print('%7d %7d%12.5f%12.5f%12.3f%12.3f%12f%12.1f' % (EPOCHS,epoch_count,ce_train,ce_valid,error_train,error_valid,l2,total_elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          cross-entropy              error-rate\n",
      "          epoch    training  validation    training  validation          L2  time (min)\n",
      "   1000       1  3148.19653  3150.28906       0.410       0.519 3142.398438         0.0\n",
      "   1000       4   365.99637   367.82031       0.016       0.583  365.911133         0.1\n",
      "   1000       7    33.76867    35.21679       0.019       0.642   33.709114         0.2\n",
      "   1000      10     4.04681     5.98684       0.016       0.589    3.999326         0.3\n",
      "   1000      13     1.74086     3.60105       0.014       0.616    1.692008         0.3\n",
      "   1000      16     1.22298     3.67702       0.019       0.562    1.150932         0.4\n",
      "   1000      19     1.02193     2.66273       0.016       0.565    0.962402         0.5\n",
      "   1000      22     0.72340     2.64349       0.018       0.589    0.662447         0.6\n",
      "   1000      25     0.60644     2.95621       0.016       0.589    0.552494         0.7\n",
      "   1000      28     0.50330     3.15534       0.037       0.562    0.413538         0.8\n",
      "   1000      31     0.42664     2.35020       0.016       0.589    0.372809         0.8\n",
      "   1000      34     0.40707     2.18356       0.018       0.589    0.351011         0.9\n",
      "   1000      37     0.31860     2.63380       0.018       0.589    0.257707         1.0\n",
      "   1000      40     0.29730     2.10537       0.016       0.589    0.236465         1.1\n",
      "   1000      43     0.26561     2.81066       0.018       0.589    0.206508         1.2\n",
      "   1000      47     0.31802     2.89847       0.019       0.535    0.264770         1.3\n",
      "   1000      50     0.39816     2.59038       0.025       0.616    0.320870         1.4\n",
      "   1000      53     0.26084     2.41224       0.016       0.616    0.215638         1.4\n",
      "   1000      56     0.25831     3.22184       0.016       0.616    0.166194         1.5\n",
      "   1000      59     0.20882     1.99767       0.016       0.589    0.160038         1.6\n",
      "   1000      62     0.21640     2.23579       0.018       0.589    0.158469         1.7\n",
      "   1000      65     0.27006     1.93295       0.016       0.616    0.216460         1.8\n",
      "   1000      68     0.40927     4.38361       0.018       0.616    0.305492         1.9\n",
      "   1000      71     0.38768     2.78146       0.016       0.562    0.342506         1.9\n",
      "   1000      75     0.30079     3.02902       0.027       0.589    0.206583         2.0\n",
      "   1000      78     0.21268     1.98950       0.018       0.616    0.143596         2.1\n",
      "   1000      81     0.26728     2.48382       0.018       0.616    0.194910         2.2\n",
      "   1000      84     0.62504     3.94415       0.025       0.616    0.523237         2.3\n",
      "   1000      87     0.18659     2.18397       0.016       0.589    0.132228         2.4\n",
      "   1000      90     0.20677     1.90022       0.016       0.589    0.149328         2.5\n",
      "   1000      93     0.18461     2.21054       0.016       0.562    0.128144         2.5\n",
      "   1000      96     0.19161     2.13467       0.016       0.616    0.142650         2.6\n",
      "   1000      99     0.47767     4.81572       0.045       0.616    0.322817         2.7\n",
      "   1000     102     0.19379     2.15497       0.019       0.535    0.136766         2.8\n",
      "   1000     105     0.20013     2.46091       0.018       0.616    0.139719         2.9\n",
      "   1000     109     0.20664     2.24358       0.018       0.669    0.138306         3.0\n",
      "   1000     112     0.22947     2.24595       0.016       0.562    0.172212         3.1\n",
      "   1000     115     0.18204     2.14166       0.018       0.616    0.122504         3.1\n",
      "   1000     118     0.20166     2.09352       0.016       0.616    0.144192         3.2\n",
      "   1000     121     0.18939     2.21481       0.019       0.562    0.130634         3.3\n",
      "   1000     124     0.22217     2.19566       0.016       0.589    0.164287         3.4\n",
      "   1000     127     0.28734     2.35614       0.016       0.589    0.223119         3.5\n",
      "   1000     130     0.23175     2.30455       0.018       0.562    0.170410         3.6\n",
      "   1000     133     0.18733     2.12748       0.016       0.562    0.131615         3.6\n",
      "   1000     136     0.26752     2.40088       0.018       0.589    0.200509         3.7\n",
      "   1000     139     0.42236     2.60750       0.018       0.589    0.354479         3.8\n",
      "   1000     142     0.19634     2.47760       0.016       0.589    0.140477         3.9\n",
      "   1000     145     0.18624     2.33898       0.016       0.616    0.131044         4.0\n",
      "   1000     149     0.18409     1.84432       0.016       0.589    0.128590         4.1\n",
      "   1000     152     0.37106     3.27167       0.016       0.616    0.316417         4.2\n",
      "   1000     155     0.19207     2.23363       0.018       0.589    0.127557         4.2\n",
      "   1000     158     0.22856     1.88656       0.018       0.562    0.161885         4.3\n",
      "   1000     161     0.17968     1.86119       0.018       0.589    0.122984         4.4\n",
      "   1000     164     0.27087     1.67604       0.032       0.589    0.154265         4.5\n",
      "   1000     167     0.17953     2.05311       0.018       0.616    0.127180         4.6\n",
      "   1000     170     0.19560     2.19803       0.018       0.562    0.134527         4.7\n",
      "   1000     173     0.26789     2.12347       0.016       0.589    0.217047         4.8\n",
      "   1000     177     0.23590     3.09547       0.016       0.616    0.145756         4.8\n",
      "   1000     180     0.22574     1.72916       0.018       0.589    0.164162         4.9\n",
      "   1000     183     0.18319     1.95648       0.018       0.616    0.127761         5.0\n",
      "   1000     186     0.19479     2.39303       0.016       0.562    0.129218         5.1\n",
      "   1000     189     0.20751     2.16013       0.016       0.589    0.153064         5.2\n",
      "   1000     192     0.21606     2.09322       0.018       0.589    0.163507         5.3\n",
      "   1000     195     0.26977     1.52948       0.032       0.562    0.191665         5.3\n",
      "   1000     198     0.20265     2.44756       0.016       0.589    0.144709         5.4\n",
      "   1000     201     0.27860     2.66367       0.022       0.704    0.158443         5.5\n",
      "   1000     204     0.18443     1.99688       0.016       0.616    0.129489         5.6\n",
      "   1000     207     0.27235     2.11848       0.016       0.562    0.221761         5.7\n",
      "   1000     210     0.21390     2.49799       0.016       0.616    0.157967         5.8\n",
      "   1000     213     0.30984     2.30668       0.016       0.589    0.249995         5.8\n",
      "   1000     216     0.29814     2.76233       0.027       0.589    0.202655         5.9\n",
      "   1000     219     0.22112     2.79960       0.016       0.589    0.147747         6.0\n",
      "   1000     222     0.18150     2.06987       0.018       0.589    0.121649         6.1\n",
      "   1000     225     0.20245     2.26211       0.018       0.589    0.136533         6.2\n",
      "   1000     228     0.23583     2.15961       0.016       0.616    0.184572         6.3\n",
      "   1000     231     0.23527     1.82755       0.032       0.589    0.153752         6.4\n",
      "   1000     234     0.24233     1.45221       0.031       0.616    0.132483         6.4\n",
      "   1000     237     0.21015     3.11334       0.016       0.589    0.128670         6.5\n",
      "   1000     240     0.32737     2.85685       0.018       0.589    0.269121         6.6\n",
      "   1000     243     0.37112     3.32373       0.018       0.616    0.314893         6.7\n",
      "   1000     246     0.28282     2.59976       0.025       0.589    0.175747         6.8\n",
      "   1000     249     0.19293     2.48926       0.016       0.616    0.139611         6.9\n",
      "   1000     252     0.21956     2.88929       0.016       0.616    0.153781         6.9\n",
      "   1000     255     0.18810     2.41789       0.016       0.589    0.127726         7.0\n",
      "   1000     258     0.24539     2.89975       0.016       0.616    0.174323         7.1\n",
      "   1000     261     0.17505     2.12290       0.016       0.616    0.119334         7.2\n",
      "   1000     264     0.21591     2.62881       0.018       0.616    0.155995         7.3\n",
      "   1000     267     0.20348     2.41483       0.016       0.589    0.142548         7.4\n",
      "   1000     270     0.23821     3.05460       0.025       0.562    0.136260         7.5\n",
      "   1000     273     0.98450     2.91221       0.185       0.723    0.515881         7.5\n",
      "   1000     276     0.18941     2.08119       0.016       0.589    0.133143         7.6\n",
      "   1000     279     0.20387     2.74715       0.016       0.589    0.124454         7.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1000     282     0.22251     2.33478       0.018       0.589    0.153632         7.8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-549a02b9f9ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mt_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mt_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Minimize MSE\n",
    "\n",
    "train = True\n",
    "\n",
    "oneHotArray = np.array([0, 1, 2, 3, 4])\n",
    "\n",
    "total_elapsed_time = 0\n",
    "\n",
    "ce_time = 0\n",
    "\n",
    "epoch_count = 0\n",
    "\n",
    "print('%15s%24s%24s' % (' ','cross-entropy','error-rate'))\n",
    "print('%15s%12s%12s%12s%12s%12s%12s' % ('epoch','training','validation','training','validation','L2','time (min)'))\n",
    "\n",
    "while(train):\n",
    "    batch = minibatch(BATCH_SIZE, N1, inputsTrain, outputsTrain)\n",
    "\n",
    "    for step in range(batch[0].shape[0]):\n",
    "        x_batch = batch[0][step]\n",
    "        y_batch = batch[1][step]\n",
    "        \n",
    "        t_start = time.time()\n",
    "        sess.run([optimizer], feed_dict={x_train:x_batch,y_train:y_batch})\n",
    "        t_end = time.time()\n",
    "        \n",
    "        total_elapsed_time += (t_end - t_start)/60\n",
    "        \n",
    "        if t_end - ce_time > 6:\n",
    "#             (ce) = sess.run(CE_train_full)\n",
    "#             print(\"cross-entropy = %f\" % (ce))\n",
    "            printStats()\n",
    "            \n",
    "            ce_time = time.time()\n",
    "\n",
    "            \n",
    "        if epoch_count >= EPOCHS:\n",
    "            train = False\n",
    "            break\n",
    "\n",
    "print(\"Finished\")\n",
    "print(\"Elapsed Time: %f\" % (total_elapsed_time))\n",
    "print(\"Epoch Count: %d\" % (epoch_count))\n",
    "\n",
    "printStats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input function for training\n",
    "inputFunc = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"input\": inputsTrain}, y=outputsTrain,\n",
    "    batch_size=BATCH_SIZE, num_epochs=EPOCHS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "def network(xDict):\n",
    "    x = xDict[\"input\"]\n",
    "    \n",
    "    input_layer = tf.reshape(x, shape=[-1, MAX_SIZE, MAX_SIZE, 1])\n",
    "    \n",
    "    input_layer = tf.cast(input_layer, tf.float32)\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=10,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    regularizer = tf.contrib.layers.l2_regularizer(scale=ALPHA)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=conv1,\n",
    "        filters=20,\n",
    "        kernel_size=[3, 3],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # Flatten for fully connected\n",
    "    flatten = tf.contrib.layers.flatten(conv2)\n",
    "    \n",
    "#     # Hidden fully connected layer\n",
    "#     layer1 = tf.layers.dense(flatten, NODES1, kernel_regularizer=regularizer, activation=tf.nn.relu)\n",
    "    # Hidden fully connected layer\n",
    "    layer2 = tf.layers.dense(flatten, 64, kernel_regularizer=regularizer, activation=tf.nn.relu)\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    outLayer = tf.layers.dense(layer2, LABEL_COUNT)\n",
    "    return outLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model function (following TF Estimator Template)\n",
    "def modelFunc(features, labels, mode):\n",
    "    # Build the neural network\n",
    "    logits = network(features)\n",
    "    \n",
    "#     resizedLogits = tf.reshape(logits, shape=[-1, MAX_SIZE * MAX_SIZE, 1])\n",
    "    \n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits)\n",
    "    \n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "    \n",
    "    print(logits.shape)\n",
    "#     print(resizedLogits.shape)\n",
    "    print(labels.shape)\n",
    "    print(pred_classes.shape)\n",
    "        \n",
    "    # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE)\n",
    "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=tf.argmax(labels, axis=1), predictions=pred_classes)\n",
    "    \n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=pred_classes,\n",
    "      loss=loss_op,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpvc01kutn\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.2\n",
      "}\n",
      ", '_evaluation_master': '', '_environment': 'local', '_tf_random_seed': None, '_model_dir': '/tmp/tmpvc01kutn', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb5dc310fd0>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_task_type': None, '_task_id': 0, '_master': '', '_num_worker_replicas': 0, '_log_step_count_steps': 100, '_is_chief': True, '_save_checkpoints_steps': None, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5}\n"
     ]
    }
   ],
   "source": [
    "# Build the Estimator\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "model = tf.estimator.Estimator(modelFunc, config=tf.contrib.learn.RunConfig(session_config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 5)\n",
      "(?, 5)\n",
      "(?,)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpvc01kutn/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.7536557, step = 1\n",
      "INFO:tensorflow:global_step/sec: 0.740544\n",
      "INFO:tensorflow:loss = 0.0857265, step = 101 (135.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.751347\n",
      "INFO:tensorflow:loss = 0.0070715337, step = 201 (133.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.744341\n",
      "INFO:tensorflow:loss = 0.011984603, step = 301 (134.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.750681\n",
      "INFO:tensorflow:loss = 0.0018688831, step = 401 (133.213 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 449 into /tmp/tmpvc01kutn/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 500 into /tmp/tmpvc01kutn/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.19548617.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7fb5dc22c400>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model\n",
    "model.train(inputFunc, steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 5)\n",
      "(?, 5)\n",
      "(?,)\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-30-15:01:54\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpvc01kutn/model.ckpt-500\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-30-15:01:59\n",
      "INFO:tensorflow:Saving dict for global step 500: accuracy = 0.41129032, global_step = 500, loss = 1.5047578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.41129032, 'global_step': 500, 'loss': 1.5047578}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "validFunc = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"input\": inputsValid}, y=outputsValid,\n",
    "    batch_size=BATCH_SIZE, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "model.evaluate(validFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputsTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
