{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, json\n",
    "import solver\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SIZE = 300\n",
    "INSTANCE_SIZE = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/features/optGenAntAsymAnalysis.pickle\")\n",
    "# # Drop rows with NA\n",
    "# rowsBefore = df.shape[0]\n",
    "# df = df.dropna()\n",
    "# print(\"Dropped %d rows due to None values\" % (rowsBefore - df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadDeepWalkInstance(path):\n",
    "    file = open(path, \"r\")\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    nodeCount = None\n",
    "    shape = None\n",
    "    \n",
    "    instance = None\n",
    "    \n",
    "    for line in file:\n",
    "        if i == 0:\n",
    "            split = line.split(\" \")\n",
    "            nodeCount = int(split[0])\n",
    "            length = int(split[1])\n",
    "            \n",
    "            instance = np.zeros(shape=(nodeCount, length))\n",
    "        else:\n",
    "            split = line.split(\" \")\n",
    "            \n",
    "            node = split[0]\n",
    "            encoding = np.array(list(map(float, split[1:])))\n",
    "            \n",
    "            instance[i - 1] = encoding\n",
    "            \n",
    "        i += 1\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    return instance\n",
    "\n",
    "def loadDeepWalkInstances(path):\n",
    "    instances = []\n",
    "    names = []\n",
    "    for file in glob.glob(path + \"*.deep\"):\n",
    "        try:\n",
    "            instance = loadDeepWalkInstance(file)\n",
    "            name = os.path.splitext(os.path.splitext(os.path.basename(file))[0])[0]\n",
    "\n",
    "            instances.append(instance)\n",
    "            names.append(name)\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    return instances, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "instances, names = loadDeepWalkInstances(\"../data/deepwalk2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "984"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"name\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge in DeepWalk data\n",
    "dwInstances = pd.DataFrame(columns=[\"name\", \"deepWalk\", \"sequenceLength\"])\n",
    "reshapedInstances = []\n",
    "for index, name in enumerate(names):\n",
    "    instance = instances[index]\n",
    "    instance = instance.reshape(-1)\n",
    "    \n",
    "    size = instance.shape[0]\n",
    "    \n",
    "    if name == \"pr2392p\":\n",
    "        continue\n",
    "    \n",
    "    if size >= INSTANCE_SIZE * MAX_SIZE:\n",
    "        print(instances[index].shape)\n",
    "        print(\"Instance %s is too large\" % (name))\n",
    "        continue\n",
    "    \n",
    "    zeroed = np.zeros((INSTANCE_SIZE * MAX_SIZE))\n",
    "    zeroed[0: size] = instance\n",
    "    \n",
    "#     instance = scale(zeroed.astype('float64')).reshape(MAX_SIZE, MAX_SIZE)\n",
    "    instance = zeroed.astype('float64').reshape(MAX_SIZE, INSTANCE_SIZE)\n",
    "        \n",
    "#     reshapedInstances.append(scale(zeroed.astype('float64')).reshape(MAX_SIZE, MAX_SIZE))\n",
    "    \n",
    "#     reshapedInstances.append(instance)\n",
    "#     instance = scale(instance.astype('float64'),axis=1)\n",
    "    dwInstances = dwInstances.append(pd.DataFrame([[name, instance, size]], columns=[\"name\", \"deepWalk\", \"sequenceLength\"]))\n",
    "    \n",
    "dwInstances = dwInstances.reset_index().drop(\"index\", axis=1)\n",
    "df = pd.merge(df, dwInstances, on=\"name\")\n",
    "df = df.drop(\"costs\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"name\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle(\"../data/largefeatures/deep300large200noscaleReshaped.pickle\")\n",
    "df = pd.read_pickle(\"../data/largefeatures/deeplarge200.pickle\")\n",
    "# df = pd.read_pickle(\"../data/largefeatures/deep128large200noscaleReshaped.pickle\")\n",
    "# df = pd.read_pickle(\"../data/largefeatures/deep300large200noscaleReshaped.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "minCostIndices = df[[\"heuristics.tabuCosts\", \"heuristics.simulatedAnnealingCosts\", \"heuristics.graspCosts\", \"heuristics.geneticCosts\", \"heuristics.antColonyCosts\"]].idxmin(axis=1)\n",
    "# minCostIndices = df[[\"heuristics.tabuCosts\", \"heuristics.simulatedAnnealingCosts\", \"heuristics.geneticCosts\", \"heuristics.antColonyCosts\"]].idxmin(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'heuristics.antColonyCosts': 1110,\n",
       "         'heuristics.geneticCosts': 19,\n",
       "         'heuristics.graspCosts': 1339,\n",
       "         'heuristics.simulatedAnnealingCosts': 16,\n",
       "         'heuristics.tabuCosts': 334})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(minCostIndices.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array(df[\"deepWalk\"].tolist())\n",
    "sequenceLengths = np.array(df[\"sequenceLength\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "costValues = df[[\"heuristics.tabuCosts\", \"heuristics.simulatedAnnealingCosts\", \"heuristics.graspCosts\", \"heuristics.geneticCosts\", \"heuristics.antColonyCosts\"]].values\n",
    "indexRankings = costValues.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 1, 3, 2, 0],\n",
       "       [4, 1, 3, 2, 0],\n",
       "       [4, 1, 3, 2, 0],\n",
       "       ..., \n",
       "       [2, 1, 0, 4, 3],\n",
       "       [0, 4, 2, 3, 1],\n",
       "       [1, 3, 2, 0, 4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexRankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intLabels = LabelEncoder().fit_transform(minCostIndices).reshape(-1, 1)\n",
    "# # 5 values for 5 different heuristics\n",
    "# # Drop grasp from analysis\n",
    "# outputs = OneHotEncoder(sparse=False, n_values=5).fit_transform(intLabels)\n",
    "\n",
    "# inputs = df\n",
    "\n",
    "size = df.shape[0]\n",
    "# Test data is separated in cleaning stage\n",
    "trainSize = int(size * 0.75)\n",
    "validSize = size - trainSize\n",
    "\n",
    "inputsTrain = inputs[0:trainSize]\n",
    "lengthsTrain = sequenceLengths[0:trainSize]\n",
    "outputsTrainUnnorm = indexRankings[0:trainSize]\n",
    "outputsTrain = normalize(outputsTrainUnnorm)\n",
    "\n",
    "inputsValid = inputs[trainSize:]\n",
    "lengthsValid = sequenceLengths[trainSize:]\n",
    "outputsValidUnnorm = indexRankings[trainSize:]\n",
    "outputsValid = normalize(outputsValidUnnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "N1 = trainSize\n",
    "LABEL_COUNT = 5\n",
    "\n",
    "NODES1 = 512\n",
    "NODES2 = 512\n",
    "NODES3 = 256\n",
    "NODES4 = 256\n",
    "NODES5 = 128\n",
    "NODES6 = 128\n",
    "NODES7 = 64\n",
    "\n",
    "LSTM_SIZE = 150\n",
    "LSTM_LAYER_COUNT = 2\n",
    "LSTM_DROPOUT_PROB = 0.7\n",
    "\n",
    "ALPHA = 0.001\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "STD = 0.1\n",
    "\n",
    "LEARNING_RATE = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input function for training\n",
    "inputFunc = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"input\": inputsTrain.astype(np.float32), \"length\": lengthsTrain.astype(np.int32)}, y=outputsTrainUnnorm.astype(np.float32),\n",
    "#     batch_size=BATCH_SIZE, num_epochs=EPOCHS, shuffle=True)\n",
    "    num_epochs=EPOCHS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.73029674,  0.18257419,  0.54772256,  0.36514837,  0.        ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputsTrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "def network(xDict, mode):\n",
    "    x = xDict[\"input\"]\n",
    "    \n",
    "    length = xDict[\"length\"]\n",
    "    \n",
    "    # Batch size, timeseries, shape, channels\n",
    "#     x = tf.reshape(x, shape=[-1, MAX_SIZE, INSTANCE_SIZE, 1])\n",
    "    \n",
    "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "        x = tf.nn.dropout(x, LSTM_DROPOUT_PROB)\n",
    "        \n",
    "#     initialCell = None\n",
    "#     lstmOutput = None\n",
    " \n",
    "    with tf.variable_scope('lstm1'):\n",
    "        initialCell = tf.contrib.rnn.LSTMBlockFusedCell(LSTM_SIZE)\n",
    "        \n",
    "        lstmOutput, _ = initialCell(x, dtype=tf.float32)\n",
    "\n",
    "        if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "            lstmOutput = tf.nn.dropout(lstmOutput, LSTM_DROPOUT_PROB)\n",
    "    \n",
    "    with tf.variable_scope('lstm2'):\n",
    "        secondCell = tf.contrib.rnn.LSTMBlockFusedCell(LSTM_SIZE)\n",
    "        \n",
    "        lstmOutput, _ = secondCell(lstmOutput, dtype=tf.float32)\n",
    "        \n",
    "        if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "            lstmOutput = tf.nn.dropout(lstmOutput, LSTM_DROPOUT_PROB)\n",
    "            \n",
    "    with tf.variable_scope('lstm3'):\n",
    "        thirdCell = tf.contrib.rnn.LSTMBlockFusedCell(LSTM_SIZE)\n",
    "        \n",
    "        lstmOutput, _ = thirdCell(lstmOutput, dtype=tf.float32)\n",
    "        \n",
    "        if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "            lstmOutput = tf.nn.dropout(lstmOutput, LSTM_DROPOUT_PROB)\n",
    "            \n",
    "    with tf.variable_scope('lstm4'):\n",
    "        fourthCell = tf.contrib.rnn.LSTMBlockFusedCell(LSTM_SIZE)\n",
    "        \n",
    "        lstmOutput, _ = fourthCell(lstmOutput, dtype=tf.float32)\n",
    "        \n",
    "        if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "            lstmOutput = tf.nn.dropout(lstmOutput, LSTM_DROPOUT_PROB)\n",
    "            \n",
    "    with tf.variable_scope('lstm5'):\n",
    "        fifthCell = tf.contrib.rnn.LSTMBlockFusedCell(LSTM_SIZE)\n",
    "        \n",
    "        lstmOutput, _ = fifthCell(lstmOutput, dtype=tf.float32)\n",
    "        \n",
    "        if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "            lstmOutput = tf.nn.dropout(lstmOutput, LSTM_DROPOUT_PROB)\n",
    "            \n",
    "    with tf.variable_scope('lstm6'):\n",
    "        sixthCell = tf.contrib.rnn.LSTMBlockFusedCell(LSTM_SIZE)\n",
    "        \n",
    "        lstmOutput, _ = sixthCell(lstmOutput, dtype=tf.float32)\n",
    "        \n",
    "        if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "            lstmOutput = tf.nn.dropout(lstmOutput, LSTM_DROPOUT_PROB)\n",
    "                \n",
    "    flatten = tf.contrib.layers.flatten(lstmOutput)\n",
    "    \n",
    "    regularizer = tf.contrib.layers.l2_regularizer(scale=ALPHA)\n",
    "    \n",
    "    # Hidden fully connected layer\n",
    "    layer1 = tf.layers.dense(flatten, NODES1, activation=tf.nn.relu)\n",
    "    layer2 = tf.layers.dense(layer1, NODES2, activation=tf.nn.relu)\n",
    "    layer3 = tf.layers.dense(layer2, NODES3, activation=tf.nn.relu)\n",
    "    layer4 = tf.layers.dense(layer3, NODES4, activation=tf.nn.relu)\n",
    "    layer5 = tf.layers.dense(layer4, NODES5, activation=tf.nn.relu)\n",
    "    layer6 = tf.layers.dense(layer5, NODES6, activation=tf.nn.relu)\n",
    "    layer7 = tf.layers.dense(layer6, NODES7, activation=tf.nn.relu)\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    outLayer = tf.layers.dense(layer7, LABEL_COUNT)\n",
    "\n",
    "    return outLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kullback-Leibler Divergence, as per https://stackoverflow.com/a/43298483\n",
    "def klDivergence(p, q):\n",
    "    pClipped = tf.clip_by_value(p, 1e-10, 1.0)\n",
    "    qClipped = tf.clip_by_value(q, 1e-10, 1.0)\n",
    "    return tf.reduce_sum(pClipped * tf.log(pClipped/qClipped))\n",
    "\n",
    "# Loss function based off of Jensen-Shannon Divergence\n",
    "def loss(label, prediction):\n",
    "    mean = 0.5 * (label + prediction)\n",
    "    return 0.5 * klDivergence(label, mean) + 0.5 * klDivergence(prediction, mean)\n",
    "\n",
    "def log2(x):\n",
    "    numerator = tf.log(x)\n",
    "    denominator = tf.log(tf.constant(2, dtype=numerator.dtype))\n",
    "    return numerator / denominator\n",
    "\n",
    "def listNetLoss(label, prediction):\n",
    "    softMaxLabel = tf.nn.softmax(label)\n",
    "    softMaxPrediction = tf.nn.softmax(prediction)\n",
    "    return -tf.reduce_mean(softMaxLabel * tf.log(softMaxPrediction))\n",
    "\n",
    "def listMLE(label, prediction):\n",
    "    sortedPrediction = tf.gather(prediction, tf.nn.top_k(label, k=5).indices)\n",
    "    final = tf.log(tf.reduce_sum(tf.exp(sortedPrediction)))\n",
    "    return tf.reduce_sum(final - sortedPrediction)\n",
    "\n",
    "def listMLE2Loss(labels, predictions, length, length64):\n",
    "    i = tf.constant(0, dtype=tf.int32)\n",
    "    innerSum = tf.constant(0, dtype=tf.float32)\n",
    "    \n",
    "    def loop(label, prediction, i, innerSum):\n",
    "        return tf.add(i, 1), tf.add(innerSum, listMLE2(label, prediction))\n",
    "    \n",
    "    cond = lambda i, _: tf.less(i, length)\n",
    "    operation = lambda i, innerSum: loop(labels[i], predictions[i], i, innerSum)\n",
    "    result = tf.while_loop(cond, operation, [i, innerSum])\n",
    "\n",
    "    return result[1]/length64\n",
    "#     return tf.constant(1.0, dtype=tf.float64) * labels + predictions\n",
    "\n",
    "def listMLE2(label, prediction):\n",
    "    # Length of vectors\n",
    "    k = tf.constant(LABEL_COUNT, dtype=tf.int32)\n",
    "    \n",
    "    sortedPrediction = tf.gather(prediction, tf.nn.top_k(label, k=k).indices)\n",
    "    \n",
    "    j = tf.constant(0, dtype=tf.int32)\n",
    "    innerSum = tf.constant(0, dtype=tf.float32)\n",
    "    cond = lambda j, _: tf.less(j, k)\n",
    "    operation = lambda j, innerSum: listMLE2Loop(sortedPrediction, j, k, innerSum)\n",
    "    result = tf.while_loop(cond, operation, [j, innerSum])\n",
    "    \n",
    "    print(result[1].shape)\n",
    "    \n",
    "    return -result[1]\n",
    "    \n",
    "def listMLE2Loop(sortedPrediction, j, k, innerSum):\n",
    "    return tf.add(j, 1), tf.add(innerSum, listMLE2Inner(sortedPrediction, j, k))\n",
    "\n",
    "def listMLE2Inner(sortedPrediction, j, k):\n",
    "    numerator = tf.exp(tf.gather(sortedPrediction, j))\n",
    "    denominator = tf.reduce_sum(tf.exp(sortedPrediction[j:k]))\n",
    "    \n",
    "    return tf.log(numerator/denominator)\n",
    "\n",
    "# Builds an integer ranking out of a 1-D tensor\n",
    "def convertPredToRank(prediction):\n",
    "    return tf.cast(tf.nn.top_k(prediction, k=5).indices, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy metric using Normalized Discounted Cumulative Gain, as per https://github.com/shiba24/learning2rank/\n",
    "def ndcg(labels, predictions, k=5):\n",
    "    topK = tf.nn.top_k(labels, k=5)\n",
    "    sortedValues = topK.values\n",
    "    sortedIndices = topK.indices\n",
    "#         print(labelSorted)\n",
    "#         labelSorted = sorted(label, reverse=True)\n",
    "    ideal_dcg = 0\n",
    "    for i in range(k):\n",
    "#             ideal_dcg += (2 ** labelSorted[:i] - 1.) / log2(tf.cast(i + 2, tf.float64))\n",
    "        ideal_dcg += (tf.cast(sortedValues[i] + 1, tf.float32)) / log2(tf.cast(i + 2, tf.float32))\n",
    "    dcg = 0\n",
    "#         argsort_indices = np.argsort(predictions)[::-1]\n",
    "#         argsort_indices = tf.nn.top_k(predictions, k=5).indices\n",
    "#         print(argsort_indices)\n",
    "    for i in range(k):\n",
    "        dcg += (tf.gather(predictions, sortedIndices[i]) + 1) / log2(tf.cast(i + 2, tf.float32))\n",
    "#         dcg += (predictions[i] + 1) / log2(tf.cast(i + 2, tf.float64))\n",
    "    return dcg / ideal_dcg\n",
    "\n",
    "def spearmanCorrelation(label, prediction):\n",
    "    length = tf.cast(tf.shape(prediction)[0], tf.float32)\n",
    "    sumVal = tf.reduce_sum(tf.square(tf.subtract(prediction, label)))\n",
    "    return 1 - 6 * sumVal / (length ** 3 - length)\n",
    "\n",
    "# Bound Spearman coeff. between 0 and 1\n",
    "def boundedSpearman(label, prediction):\n",
    "    return (spearmanCorrelation(label, prediction) + 1.)/2\n",
    "\n",
    "def top1Match(label, prediction):\n",
    "    return tf.cast(tf.equal(label[0], prediction[0]), tf.float32)\n",
    "\n",
    "def top2Match(label, prediction):\n",
    "    sameFirstOrSecond = tf.logical_or(tf.equal(label[0], prediction[0]), tf.equal(label[1], prediction[1]))\n",
    "    sameFirstAndSecond = tf.logical_or(tf.equal(label[1], prediction[0]), tf.equal(label[0], prediction[1]))\n",
    "    return tf.cast(tf.logical_or(sameFirstOrSecond, sameFirstAndSecond), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the model function (following TF Estimator Template)\n",
    "# def modelFunc(features, labels, mode):\n",
    "#     # Build the neural network\n",
    "#     logits = network(features)\n",
    "    \n",
    "# #     resizedLogits = tf.reshape(logits, shape=[-1, MAX_SIZE * MAX_SIZE, 1])\n",
    "    \n",
    "#     # Predictions\n",
    "#     # TODO: Possibly need to change\n",
    "#     pred_classes = logits\n",
    "# #     pred_classes = tf.argmax(logits, axis=1)\n",
    "# #     pred_probas = tf.nn.softmax(logits)\n",
    "#     pred_probas = tf.nn.sigmoid(logits)\n",
    "    \n",
    "#     # If prediction mode, early return\n",
    "#     if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "#         return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "    \n",
    "#     print(logits.shape)\n",
    "# #     print(resizedLogits.shape)\n",
    "#     print(labels.shape)\n",
    "#     print(pred_classes.shape)\n",
    "        \n",
    "#     # Define loss and optimizer\n",
    "# #     loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "# #         logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "#     loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "#         logits=logits, labels=labels))\n",
    "#     optimizer = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE)\n",
    "#     train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    \n",
    "#     # Evaluate the accuracy of the model\n",
    "# #     acc_op = tf.metrics.accuracy(labels=tf.argmax(labels, axis=1), predictions=pred_classes)\n",
    "#     acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "    \n",
    "#     # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "#     # the different ops for training, evaluating, ...\n",
    "#     estim_specs = tf.estimator.EstimatorSpec(\n",
    "#       mode=mode,\n",
    "#       predictions=pred_classes,\n",
    "#       loss=loss_op,\n",
    "#       train_op=train_op,\n",
    "#       eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "#     return estim_specs\n",
    "\n",
    "# Define the model function (following TF Estimator Template)\n",
    "def modelFunc(features, labels, mode):\n",
    "    # Build the neural network\n",
    "    logits = network(features, mode)\n",
    "    \n",
    "#     resizedLogits = tf.reshape(logits, shape=[-1, MAX_SIZE * MAX_SIZE, 1])\n",
    "    \n",
    "    # Predictions\n",
    "    # TODO: Possibly need to change\n",
    "#     pred_classes = logits\n",
    "    pred_classes = tf.map_fn(convertPredToRank, logits)\n",
    "#     pred_classes = tf.argmax(logits, axis=1)\n",
    "#     pred_probas = tf.nn.softmax(logits)\n",
    "    \n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "#     loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "#         logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "#     loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "#         logits=logits, labels=labels))\n",
    "#     loss_op = tf.reduce_mean(loss(labels, logits))\n",
    "    loss_op = tf.reduce_mean(listNetLoss(labels, logits))\n",
    "#     loss_map = tf.map_fn(lambda x: listMLE2(x[0], x[1]), (labels, pred_classes), dtype=tf.float64)\n",
    "#     print(labels.get_shape()[0])\n",
    "#     labels_length = tf.shape(labels)[0]\n",
    "#     loss_op = tf.reduce_mean(listMLE2Loss(labels, logits, labels_length, tf.cast(labels_length, dtype=tf.float32)))\n",
    "#     optimizer = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE)\n",
    "    optimizer = tf.contrib.opt.NadamOptimizer(learning_rate=LEARNING_RATE)\n",
    "#     optimizer = tf.train.AdamOptimizer()\n",
    "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # Evaluate the accuracy of the model\n",
    "#     acc_op = tf.metrics.accuracy(labels=tf.argmax(labels, axis=1), predictions=pred_classes)\n",
    "#     acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "    ndcg_map = tf.map_fn(lambda x: ndcg(x[0], x[1]), (labels, pred_classes), dtype=tf.float32)\n",
    "    ndcg_op = tf.metrics.mean(ndcg_map)\n",
    "    top1_map = tf.map_fn(lambda x: top1Match(x[0], x[1]), (labels, pred_classes), dtype=tf.float32)\n",
    "    top1_op = tf.metrics.mean(top1_map)\n",
    "    top2_map = tf.map_fn(lambda x: top2Match(x[0], x[1]), (labels, pred_classes), dtype=tf.float32)\n",
    "    top2_op = tf.metrics.mean(top2_map)\n",
    "    spearman_map = tf.map_fn(lambda x: boundedSpearman(x[0], x[1]), (labels, pred_classes), dtype=tf.float32)\n",
    "    acc_op = tf.metrics.mean(spearman_map)\n",
    "    \n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=pred_classes,\n",
    "      loss=loss_op,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops={'accuracy': acc_op, 'ndcg': ndcg_op, 'top1Classification': top1_op, 'top2Classification': top2_op})\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpebpl_zif\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3c84302e10>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': , '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmpebpl_zif'}\n"
     ]
    }
   ],
   "source": [
    "# Build the Estimator\n",
    "config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "model = tf.estimator.Estimator(modelFunc, config=tf.contrib.learn.RunConfig(session_config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainResults = []\n",
    "validResults = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor of shape [45000,512] and type float\n\t [[Node: dense/kernel/Adam/Initializer/zeros = Const[_class=[\"loc:@dense/kernel\"], dtype=DT_FLOAT, value=Tensor<type: float shape: [45000,512] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'dense/kernel/Adam/Initializer/zeros', defined at:\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-23-19b6134e96fa>\", line 10, in <module>\n    model.train(inputFunc, steps=10000)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 241, in train\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 630, in _train_model\n    model_fn_lib.ModeKeys.TRAIN)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 615, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"<ipython-input-17-990683226416>\", line 79, in modelFunc\n    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 325, in minimize\n    name=name)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 446, in apply_gradients\n    self._create_slots([_get_variable_for(v) for v in var_list])\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 132, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 766, in _zeros_slot\n    named_slots[_var_key(var)] = slot_creator.create_zeros_slot(var, op_name)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 174, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 146, in create_slot_with_initializer\n    dtype)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 66, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1065, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 962, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 367, in get_variable\n    validate_shape=validate_shape, use_resource=use_resource)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 352, in _true_getter\n    use_resource=use_resource)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 725, in _get_single_variable\n    validate_shape=validate_shape)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 199, in __init__\n    expected_shape=expected_shape)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 277, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 701, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py\", line 93, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1401, in zeros\n    output = constant(zero, shape=shape, dtype=dtype, name=name)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 106, in constant\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [45000,512] and type float\n\t [[Node: dense/kernel/Adam/Initializer/zeros = Const[_class=[\"loc:@dense/kernel\"], dtype=DT_FLOAT, value=Tensor<type: float shape: [45000,512] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [45000,512] and type float\n\t [[Node: dense/kernel/Adam/Initializer/zeros = Const[_class=[\"loc:@dense/kernel\"], dtype=DT_FLOAT, value=Tensor<type: float shape: [45000,512] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-19b6134e96fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# for i in range(0, 30):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputFunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating Train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps)\u001b[0m\n\u001b[1;32m    239\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m    681\u001b[0m           \u001b[0msave_summaries_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_summary_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m           log_step_count_steps=self._config.log_step_count_steps) as mon_sess:\n\u001b[0m\u001b[1;32m    684\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mMonitoredTrainingSession\u001b[0;34m(master, is_chief, checkpoint_dir, scaffold, hooks, chief_only_hooks, save_checkpoint_secs, save_summaries_steps, save_summaries_secs, config, stop_grace_period_secs, log_step_count_steps)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0mall_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m   return MonitoredSession(session_creator=session_creator, hooks=all_hooks,\n\u001b[0;32m--> 365\u001b[0;31m                           stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    666\u001b[0m     super(MonitoredSession, self).__init__(\n\u001b[1;32m    667\u001b[0m         \u001b[0msession_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[1;32m    489\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess_creator)\u001b[0m\n\u001b[1;32m    840\u001b[0m     \"\"\"\n\u001b[1;32m    841\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m     \u001b[0m_WrappedSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    845\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         logging.info('An error was raised while a session was being created. '\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    549\u001b[0m       \u001b[0;34m\"\"\"Creates a coordinated session.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m       \u001b[0;31m# Keep the tf_sess for unit testing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m       \u001b[0;31m# We don't want coordinator to suppress any exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_stop_exception_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0minit_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0minit_feed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         init_fn=self._scaffold.init_fn)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/session_manager.py\u001b[0m in \u001b[0;36mprepare_session\u001b[0;34m(self, master, init_op, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config, init_feed_dict, init_fn)\u001b[0m\n\u001b[1;32m    277\u001b[0m                            \"init_fn or local_init_op was given\")\n\u001b[1;32m    278\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minit_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minit_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0minit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [45000,512] and type float\n\t [[Node: dense/kernel/Adam/Initializer/zeros = Const[_class=[\"loc:@dense/kernel\"], dtype=DT_FLOAT, value=Tensor<type: float shape: [45000,512] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'dense/kernel/Adam/Initializer/zeros', defined at:\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-23-19b6134e96fa>\", line 10, in <module>\n    model.train(inputFunc, steps=10000)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 241, in train\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 630, in _train_model\n    model_fn_lib.ModeKeys.TRAIN)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 615, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"<ipython-input-17-990683226416>\", line 79, in modelFunc\n    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 325, in minimize\n    name=name)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 446, in apply_gradients\n    self._create_slots([_get_variable_for(v) for v in var_list])\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/adam.py\", line 132, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 766, in _zeros_slot\n    named_slots[_var_key(var)] = slot_creator.create_zeros_slot(var, op_name)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 174, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 146, in create_slot_with_initializer\n    dtype)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\", line 66, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1065, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 962, in get_variable\n    use_resource=use_resource, custom_getter=custom_getter)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 367, in get_variable\n    validate_shape=validate_shape, use_resource=use_resource)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 352, in _true_getter\n    use_resource=use_resource)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 725, in _get_single_variable\n    validate_shape=validate_shape)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 199, in __init__\n    expected_shape=expected_shape)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 277, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 701, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py\", line 93, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1401, in zeros\n    output = constant(zero, shape=shape, dtype=dtype, name=name)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 106, in constant\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [45000,512] and type float\n\t [[Node: dense/kernel/Adam/Initializer/zeros = Const[_class=[\"loc:@dense/kernel\"], dtype=DT_FLOAT, value=Tensor<type: float shape: [45000,512] values: [0 0 0]...>, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "trainFunc = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"input\": inputsTrain.astype(np.float32)}, y=outputsTrain.astype(np.float32),\n",
    "    batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "validFunc = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"input\": inputsValid.astype(np.float32)}, y=outputsValid.astype(np.float32),\n",
    "    batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# for i in range(0, 30):\n",
    "model.train(inputFunc, steps=10000)\n",
    "\n",
    "print(\"Evaluating Train\")\n",
    "accuracy = model.evaluate(trainFunc)\n",
    "trainResults.append(accuracy)\n",
    "\n",
    "print(\"Evaluating Valid\")\n",
    "accuracy = model.evaluate(validFunc)\n",
    "validResults.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(model.predict(validFunc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'[ 2.  0.  3.  4.  1.]': 35, '[ 2.  0.  4.  3.  1.]': 271})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(list(map(str, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'[0 1 2 4 3]': 1,\n",
       "         '[0 2 1 4 3]': 12,\n",
       "         '[0 2 4 1 3]': 83,\n",
       "         '[0 2 4 3 1]': 2,\n",
       "         '[1 2 4 0 3]': 1,\n",
       "         '[1 4 2 0 3]': 1,\n",
       "         '[1 4 2 3 0]': 1,\n",
       "         '[2 0 1 3 4]': 1,\n",
       "         '[2 0 1 4 3]': 37,\n",
       "         '[2 0 4 1 3]': 379,\n",
       "         '[2 0 4 3 1]': 5,\n",
       "         '[2 1 0 4 3]': 1,\n",
       "         '[2 1 4 0 3]': 5,\n",
       "         '[2 1 4 3 0]': 1,\n",
       "         '[2 3 1 4 0]': 1,\n",
       "         '[2 4 0 1 3]': 33,\n",
       "         '[2 4 0 3 1]': 3,\n",
       "         '[2 4 1 0 3]': 6,\n",
       "         '[2 4 1 3 0]': 1,\n",
       "         '[2 4 3 1 0]': 1,\n",
       "         '[3 1 4 2 0]': 1,\n",
       "         '[4 1 2 3 0]': 7,\n",
       "         '[4 1 3 0 2]': 38,\n",
       "         '[4 1 3 2 0]': 273,\n",
       "         '[4 2 0 1 3]': 3,\n",
       "         '[4 2 0 3 1]': 1,\n",
       "         '[4 2 1 0 3]': 4,\n",
       "         '[4 3 1 2 0]': 13})"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(list(map(str, outputsTrainUnnorm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
